{"id": "de739617-d992-4103-a10e-c89b16f6a9b9", "code": "# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid optimization algorithm combining simulated annealing with local search.\n    Escapes local minima through temperature-based acceptance and adaptive step sizes.\n    \"\"\"\n    # Initialize with multiple starting points for better coverage\n    num_starts = 5\n    best_results = []\n    \n    for start in range(num_starts):\n        # Enhanced simulated annealing parameters\n        temp = 2.0  # Higher initial temperature for better exploration\n        initial_temp = temp\n        # Adaptive cooling: faster cooling when temperature is high, slower when low\n        base_cooling = 0.995\n        # Also add occasional reheating to escape deep local minima\n        reheat_frequency = iterations // (num_starts * 4)\n        \n        # Initialize current point\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(x, y)\n        \n        best_x, best_y, best_value = x, y, current_value\n        \n        # Adaptive step size based on bounds\n        step_size = (bounds[1] - bounds[0]) * 0.1\n        \n        # Initialize momentum\n        momentum_x, momentum_y = 0, 0\n        \n        for i in range(iterations // num_starts):\n            # Adaptive step size based on iteration progress and temperature\n            progress = i / (iterations // num_starts)\n            temp_ratio = temp  # Temperature affects step size\n            current_step_size = step_size * (1 - progress) * temp_ratio\n            \n            # Generate candidate with momentum and Gaussian perturbation\n            random_dx = np.random.normal(0, current_step_size)\n            random_dy = np.random.normal(0, current_step_size)\n            \n            # Combine momentum with random walk (momentum helps escape local minima)\n            dx = 0.3 * momentum_x + 0.7 * random_dx\n            dy = 0.3 * momentum_y + 0.7 * random_dy\n            \n            candidate_x = x + dx\n            candidate_y = y + dy\n            \n            # Ensure bounds\n            candidate_x = np.clip(candidate_x, bounds[0], bounds[1])\n            candidate_y = np.clip(candidate_y, bounds[0], bounds[1])\n            \n            candidate_value = evaluate_function(candidate_x, candidate_y)\n            \n            # Accept if better, or with enhanced temperature-based probability\n            if candidate_value < current_value:\n                x, y, current_value = candidate_x, candidate_y, candidate_value\n                if candidate_value < best_value:\n                    best_x, best_y, best_value = candidate_x, candidate_y, candidate_value\n                # Update momentum in direction of improvement\n                momentum_x = dx * 0.5\n                momentum_y = dy * 0.5\n            else:\n                # Enhanced acceptance for escaping local minima\n                delta = candidate_value - current_value\n                # Adaptive acceptance based on search progress and temperature\n                progress_factor = 1.0 + (iterations // num_starts - i) / (iterations // num_starts)\n                acceptance_prob = np.exp(-delta / (temp * progress_factor))\n                \n                if np.random.random() < acceptance_prob:\n                    x, y, current_value = candidate_x, candidate_y, candidate_value\n                    # Reduce momentum on uphill moves but don't zero it\n                    momentum_x *= 0.3\n                    momentum_y *= 0.3\n                else:\n                    # Decay momentum when move is rejected\n                    momentum_x *= 0.8\n                    momentum_y *= 0.8\n            \n            # Adaptive cooling based on temperature level\n            if temp > initial_temp * 0.5:\n                temp *= base_cooling  # Normal cooling\n            else:\n                temp *= (base_cooling + 0.002)  # Slower cooling at low temperatures\n            \n            # Occasional reheating to escape deep local minima\n            if i % reheat_frequency == 0 and i > 0 and temp < initial_temp * 0.1:\n                temp = min(temp * 2.0, initial_temp * 0.3)\n        \n        best_results.append((best_x, best_y, best_value))\n    \n    # Get the best result from all starts\n    best_x, best_y, best_value = min(best_results, key=lambda x: x[2])\n    \n    # Final local refinement phase\n    refinement_steps = iterations // 20\n    refinement_step_size = (bounds[1] - bounds[0]) * 0.005\n    \n    for i in range(refinement_steps):\n        # Very small Gaussian perturbations for fine-tuning\n        dx = np.random.normal(0, refinement_step_size * (1 - i/refinement_steps))\n        dy = np.random.normal(0, refinement_step_size * (1 - i/refinement_steps))\n        \n        new_x = np.clip(best_x + dx, bounds[0], bounds[1])\n        new_y = np.clip(best_y + dy, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n        \n        if new_value < best_value:\n            best_x, best_y, best_value = new_x, new_y, new_value\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n", "language": "python", "parent_id": "3b46b243-4e8e-4afb-8d4f-6fdfe0960663", "generation": 2, "timestamp": 1765020447.9160762, "iteration_found": 16, "metrics": {"runs_successfully": 1.0, "value_score": 0.9996807775320596, "distance_score": 0.9976431461795676, "combined_score": 1.4986999989298502, "reliability_score": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 6 lines with 19 lines\nChange 2: Replace 11 lines with 24 lines\nChange 3: Replace 3 lines with 7 lines\nChange 4: Replace 2 lines with 9 lines\nChange 5: Replace 2 lines with 20 lines", "parent_metrics": {"runs_successfully": 1.0, "value_score": 0.9823971624301019, "distance_score": 0.6829181492498293, "combined_score": 1.3441110389849995, "reliability_score": 1.0}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve a function minimization algorithm to find the global minimum of a complex function with many local minima. The function is f(x, y) = sin(x) * cos(y) + sin(x*y) + (x^2 + y^2)/20. Focus on improving the search_algorithm function to reliably find the global minimum, escaping local minima that might trap simple algorithms.", "user": "# Current Program Information\n- Fitness: 1.3441\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness declined: 1.4962 \u2192 1.3441. Consider revising recent changes.\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### stage1_result\n```\nFound solution at x=-1.7296, y=0.6643 with value=-1.5181\n```\n\n### distance_to_global\n```\n0.0290\n```\n\n### solution_quality\n```\nDistance < 0.5: Very close\n```\n\n### convergence_info\n```\nConverged in 10 trials with 10 successes\n```\n\n### best_position\n```\nFinal position: x=-1.5875, y=0.6857\n```\n\n### average_distance_to_global\n```\n0.4643\n```\n\n### search_efficiency\n```\nSuccess rate: 100.00%\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 27 lines with 80 lines\n- Metrics: runs_successfully: 1.0000, value_score: 0.9996, distance_score: 0.9922, combined_score: 1.4962, reliability_score: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Change 1: Replace 56 lines with 76 lines\n- Metrics: runs_successfully: 1.0000, value_score: 0.9996, distance_score: 0.9934, combined_score: 1.4967, reliability_score: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Change 1: Replace 27 lines with 78 lines\n- Metrics: runs_successfully: 1.0000, value_score: 0.9997, distance_score: 0.9995, combined_score: 1.4995, reliability_score: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.4995)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Adaptive differential evolution with local search hybrid.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Population size\n    pop_size = 20\n    \n    # Initialize population\n    population = np.random.uniform(bounds[0], bounds[1], (pop_size, 2))\n    values = np.array([evaluate_function(x, y) for x, y in population])\n    \n    # Track best solution\n    best_idx = np.argmin(values)\n    best_x, best_y = population[best_idx]\n    best_value = values[best_idx]\n    \n    # Adaptive parameters\n    mutation_factor = 0.8\n    crossover_prob = 0.7\n    \n    for i in range(iterations):\n        # Adaptive parameters based on progress\n        progress = i / iterations\n        mutation_factor = 0.5 + 0.3 * (1 - progress)\n        crossover_prob = 0.5 + 0.2 * (1 - progress)\n        \n        for j in range(pop_size):\n            # Select three random individuals (different from j)\n            candidates = list(range(pop_size))\n            candidates.remove(j)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Differential mutation\n            mutant = population[a] + mutation_factor * (population[b] - population[c])\n            \n            # Crossover\n            trial = population[j].copy()\n            crossover_mask = np.random.random(2) < crossover_prob\n            trial[crossover_mask] = mutant[crossover_mask]\n            \n            # Ensure bounds\n            trial = np.clip(trial, bounds[0], bounds[1])\n            \n            # Evaluate trial\n            trial_value = evaluate_function(trial[0], trial[1])\n            \n            # Selection\n            if trial_value < values[j]:\n                population[j] = trial\n                values[j] = trial_value\n                \n                # Update global best\n                if trial_value < best_value:\n                    best_x, best_y = trial[0], trial[1]\n                    best_value = trial_value\n        \n        # Periodic local search around best solution\n        if i % 50 == 0 and i > 0:\n            local_step = 0.1 * (1 - progress)\n            for _ in range(10):\n                local_x = best_x + np.random.normal(0, local_step)\n                local_y = best_y + np.random.normal(0, local_step)\n                local_x = np.clip(local_x, bounds[0], bounds[1])\n                local_y = np.clip(local_y, bounds[0], bounds[1])\n                local_value = evaluate_function(local_x, local_y)\n                \n                if local_value < best_value:\n                    best_x, best_y = local_x, local_y\n                    best_value = local_value\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9997), Performs well on distance_score (0.9995), Performs well on combined_score (1.4995), Performs well on reliability_score (1.0000)\n\n### Program 2 (Score: 1.4967)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Advanced hybrid search combining simulated annealing, local search, and multi-start strategy.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n    \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start with 5 candidates for better coverage (increased from 3)\n    candidates = []\n    for _ in range(5):\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        value = evaluate_function(x, y)\n        candidates.append((x, y, value))\n    \n    # Simulated annealing parameters with better cooling schedule\n    initial_temp = 10.0\n    final_temp = 0.01\n    cooling_rate = (final_temp / initial_temp) ** (1.0 / iterations)\n    temperature = initial_temp\n    \n    # Track global best for better convergence\n    best_idx = min(range(5), key=lambda i: candidates[i][2])\n    best_x, best_y, best_value = candidates[best_idx]\n    \n    for i in range(iterations):\n        # Update temperature with exponential cooling\n        temperature *= cooling_rate\n        \n        for j, (x, y, current_value) in enumerate(candidates):\n            # Adaptive step size based on iteration progress\n            if i < iterations // 3:\n                # Early exploration: larger steps\n                step_scale = 2.0 * (1 - i/iterations)\n            else:\n                # Late refinement: smaller steps focused around best\n                step_scale = max(0.1, 0.5 * (1 - i/iterations))\n            \n            # Local perturbation with Gaussian noise\n            new_x = x + np.random.normal(0, step_scale)\n            new_y = y + np.random.normal(0, step_scale)\n            \n            # Keep within bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            \n            new_value = evaluate_function(new_x, new_y)\n            \n            # Accept if better, or with probability if worse (simulated annealing)\n            delta = new_value - current_value\n            if delta < 0 or (temperature > 0.1 and np.random.random() < np.exp(-delta / temperature)):\n                candidates[j] = (new_x, new_y, new_value)\n                \n                # Update global best when we find a better solution\n                if new_value < best_value:\n                    best_value = new_value\n                    best_x, best_y = new_x, new_y\n        \n        # Strategic long-range exploration: replace worst candidate\n        if i % (iterations // 8) == 0 and i > 0:\n            worst_idx = max(range(5), key=lambda i: candidates[i][2])\n            x = np.random.uniform(bounds[0], bounds[1])\n            y = np.random.uniform(bounds[0], bounds[1])\n            value = evaluate_function(x, y)\n            candidates[worst_idx] = (x, y, value)\n            \n            # Update global best if needed\n            if value < best_value:\n                best_value = value\n                best_x, best_y = x, y\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9996), Performs well on distance_score (0.9934), Performs well on combined_score (1.4967), Performs well on reliability_score (1.0000)\n\n### Program 3 (Score: 1.4962)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid simulated annealing with local refinement to escape local minima.\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multiple restarts from different starting points\n    num_restarts = 5\n    restart_iterations = iterations // num_restarts\n    \n    best_global_x = np.random.uniform(bounds[0], bounds[1])\n    best_global_y = np.random.uniform(bounds[0], bounds[1])\n    best_global_value = evaluate_function(best_global_x, best_global_y)\n    \n    for restart in range(num_restarts):\n        # Initialize restart point\n        if restart == 0:\n            x, y = best_global_x, best_global_y\n        else:\n            x = np.random.uniform(bounds[0], bounds[1])\n            y = np.random.uniform(bounds[0], bounds[1])\n        \n        current_value = evaluate_function(x, y)\n        best_restart_value = current_value\n        best_restart_x, best_restart_y = x, y\n        \n        # Initial temperature for simulated annealing\n        temp = 2.0\n        temp_decay = 0.95\n        \n        for i in range(restart_iterations):\n            # Adaptive step size based on iteration progress\n            step_scale = max(0.1, 2.0 * (1 - i/restart_iterations))\n            \n            # Generate candidate with local search bias\n            if i < restart_iterations * 0.7:\n                # Global exploration with simulated annealing\n                dx = np.random.normal(0, step_scale)\n                dy = np.random.normal(0, step_scale)\n            else:\n                # Local refinement around best point\n                dx = np.random.normal(0, step_scale * 0.3)\n                dy = np.random.normal(0, step_scale * 0.3)\n            \n            new_x = np.clip(x + dx, bounds[0], bounds[1])\n            new_y = np.clip(y + dy, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n            \n            # Accept or reject based on simulated annealing\n            if new_value < current_value:\n                # Always accept better solutions\n                x, y = new_x, new_y\n                current_value = new_value\n            else:\n                # Sometimes accept worse solutions to escape local minima\n                delta = new_value - current_value\n                prob = np.exp(-delta / temp)\n                if np.random.random() < prob:\n                    x, y = new_x, new_y\n                    current_value = new_value\n            \n            # Update best for this restart\n            if current_value < best_restart_value:\n                best_restart_value = current_value\n                best_restart_x, best_restart_y = x, y\n            \n            # Cool down temperature\n            temp *= temp_decay\n        \n        # Update global best\n        if best_restart_value < best_global_value:\n            best_global_value = best_restart_value\n            best_global_x, best_global_y = best_restart_x, best_restart_y\n    \n    return best_global_x, best_global_y, best_global_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9996), Performs well on distance_score (0.9922), Performs well on combined_score (1.4962), Performs well on reliability_score (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 1.3441)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid optimization algorithm combining simulated annealing with local search.\n    Escapes local minima through temperature-based acceptance and adaptive step sizes.\n    \"\"\"\n    # Initialize with multiple starting points for better coverage\n    num_starts = 5\n    best_results = []\n    \n    for start in range(num_starts):\n        # Simulated annealing parameters\n        temp = 1.0\n        cooling_rate = 0.995\n        \n        # Initialize current point\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(x, y)\n        \n        best_x, best_y, best_value = x, y, current_value\n        \n        # Adaptive step size based on bounds\n        step_size = (bounds[1] - bounds[0]) * 0.1\n        \n        for i in range(iterations // num_starts):\n            # Generate candidate with adaptive step size\n            angle = np.random.uniform(0, 2 * np.pi)\n            step = step_size * (1 - i / (iterations // num_starts))  # Decrease step size\n            candidate_x = x + step * np.cos(angle)\n            candidate_y = y + step * np.sin(angle)\n            \n            # Ensure bounds\n            candidate_x = np.clip(candidate_x, bounds[0], bounds[1])\n            candidate_y = np.clip(candidate_y, bounds[0], bounds[1])\n            \n            candidate_value = evaluate_function(candidate_x, candidate_y)\n            \n            # Accept if better, or with temperature-based probability\n            if candidate_value < current_value:\n                x, y, current_value = candidate_x, candidate_y, candidate_value\n                if candidate_value < best_value:\n                    best_x, best_y, best_value = candidate_x, candidate_y, candidate_value\n            else:\n                # Accept worse solutions with decreasing probability\n                delta = candidate_value - current_value\n                prob = np.exp(-delta / temp)\n                if np.random.random() < prob:\n                    x, y, current_value = candidate_x, candidate_y, candidate_value\n            \n            # Cool down temperature\n            temp *= cooling_rate\n        \n        best_results.append((best_x, best_y, best_value))\n    \n    # Return the best result from all starts\n    return min(best_results, key=lambda x: x[2])\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to value_score\n\n### Program D2 (Score: 1.4910)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Advanced hybrid optimization algorithm combining multiple strategies\n    to escape local minima and find the global minimum.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n    \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start strategy: maintain multiple candidates\n    num_candidates = 5\n    candidates = []\n    for _ in range(num_candidates):\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        candidates.append((x, y, evaluate_function(x, y)))\n    \n    # Simulated annealing parameters\n    initial_temp = 10.0\n    final_temp = 0.01\n    cooling_rate = (final_temp / initial_temp) ** (1.0 / iterations)\n    temperature = initial_temp\n    \n    # Adaptive step size\n    step_size = (bounds[1] - bounds[0]) * 0.1\n    min_step_size = (bounds[1] - bounds[0]) * 0.001\n    \n    # Track best solution\n    best_idx = min(range(num_candidates), key=lambda i: candidates[i][2])\n    best_x, best_y, best_value = candidates[best_idx]\n    \n    for iter in range(iterations):\n        # Update temperature\n        temperature *= cooling_rate\n        \n        # Try to improve each candidate\n        for i in range(num_candidates):\n            x, y, value = candidates[i]\n            \n            # Local refinement with adaptive step\n            if iter > iterations // 4:  # Start local refinement after initial exploration\n                dx = np.random.normal(0, step_size)\n                dy = np.random.normal(0, step_size)\n            else:\n                # Global search with larger steps\n                dx = np.random.uniform(-step_size * 3, step_size * 3)\n                dy = np.random.uniform(-step_size * 3, step_size * 3)\n            \n            new_x = np.clip(x + dx, bounds[0], bounds[1])\n            new_y = np.clip(y + dy, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n            \n            # Accept or reject based on simulated annealing\n            delta = new_value - value\n            if delta < 0 or (temperature > 0.1 and np.random.random() < np.exp(-delta / temperature)):\n                candidates[i] = (new_x, new_y, new_value)\n                \n                # Update global best\n                if new_value < best_value:\n                    best_value = new_value\n                    best_x, best_y = new_x, new_y\n                    # Reduce step size when we find a better solution\n                    step_size = max(step_size * 0.9, min_step_size)\n        \n        # Occasional random restart to escape deep local minima\n        if iter % (iterations // 10) == 0 and iter > 0:\n            worst_idx = max(range(num_candidates), key=lambda i: candidates[i][2])\n            candidates[worst_idx] = (\n                np.random.uniform(bounds[0], bounds[1]),\n                np.random.uniform(bounds[0], bounds[1]),\n                evaluate_function(candidates[worst_idx][0], candidates[worst_idx][1])\n            )\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to value_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 1.4995, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Adaptive differential evolution with local search hybrid.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Population size\n    pop_size = 20\n    \n    # Initialize population\n    population = np.random.uniform(bounds[0], bounds[1], (pop_size, 2))\n    values = np.array([evaluate_function(x, y) for x, y in population])\n    \n    # Track best solution\n    best_idx = np.argmin(values)\n    best_x, best_y = population[best_idx]\n    best_value = values[best_idx]\n    \n    # Adaptive parameters\n    mutation_factor = 0.8\n    crossover_prob = 0.7\n    \n    for i in range(iterations):\n        # Adaptive parameters based on progress\n        progress = i / iterations\n        mutation_factor = 0.5 + 0.3 * (1 - progress)\n        crossover_prob = 0.5 + 0.2 * (1 - progress)\n        \n        for j in range(pop_size):\n            # Select three random individuals (different from j)\n            candidates = list(range(pop_size))\n            candidates.remove(j)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Differential mutation\n            mutant = population[a] + mutation_factor * (population[b] - population[c])\n            \n            # Crossover\n            trial = population[j].copy()\n            crossover_mask = np.random.random(2) < crossover_prob\n            trial[crossover_mask] = mutant[crossover_mask]\n            \n            # Ensure bounds\n            trial = np.clip(trial, bounds[0], bounds[1])\n            \n            # Evaluate trial\n            trial_value = evaluate_function(trial[0], trial[1])\n            \n            # Selection\n            if trial_value < values[j]:\n                population[j] = trial\n                values[j] = trial_value\n                \n                # Update global best\n                if trial_value < best_value:\n                    best_x, best_y = trial[0], trial[1]\n                    best_value = trial_value\n        \n        # Periodic local search around best solution\n        if i % 50 == 0 and i > 0:\n            local_step = 0.1 * (1 - progress)\n            for _ in range(10):\n                local_x = best_x + np.random.normal(0, local_step)\n                local_y = best_y + np.random.normal(0, local_step)\n                local_x = np.clip(local_x, bounds[0], bounds[1])\n                local_y = np.clip(local_y, bounds[0], bounds[1])\n                local_value = evaluate_function(local_x, local_y)\n                \n                if local_value < best_value:\n                    best_x, best_y = local_x, local_y\n                    best_value = local_value\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Modification: Change 1: Replace 27 lines with 78 lines, Excellent runs_successfully (1.000), Excellent value_score (1.000)\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid simulated annealing with local refinement to escape local minima.\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multiple restarts from different starting points\n    num_restarts = 5\n    restart_iterations = iterations // num_restarts\n    \n    best_global_x = np.random.uniform(bounds[0], bounds[1])\n    best_global_y = np.random.uniform(bounds[0], bounds[1])\n    best_global_value = evaluate_function(best_global_x, best_global_y)\n    \n    for restart in range(num_restarts):\n        # Initialize restart point\n        if restart == 0:\n            x, y = best_global_x, best_global_y\n        else:\n            x = np.random.uniform(bounds[0], bounds[1])\n            y = np.random.uniform(bounds[0], bounds[1])\n        \n        current_value = evaluate_function(x, y)\n        best_restart_value = current_value\n        best_restart_x, best_restart_y = x, y\n        \n        # Initial temperature for simulated annealing with adaptive scheduling\n        temp = 5.0\n        initial_temp = temp\n        # Adaptive temperature decay based on search progress\n        temp_decay = 0.98 if restart == 0 else 0.95\n        \n        for i in range(restart_iterations):\n            # Adaptive step size based on both iteration progress and temperature\n            temp_ratio = temp / initial_temp\n            step_scale = max(0.05, 2.0 * (1 - i/restart_iterations) * temp_ratio)\n            \n            # Generate candidate with momentum and adaptive search strategy\n            if i == 0:\n                # Initialize momentum\n                momentum_x, momentum_y = 0, 0\n            \n            if i < restart_iterations * 0.6:\n                # Global exploration with momentum\n                random_dx = np.random.normal(0, step_scale)\n                random_dy = np.random.normal(0, step_scale)\n                dx = 0.3 * momentum_x + 0.7 * random_dx\n                dy = 0.3 * momentum_y + 0.7 * random_dy\n            elif i < restart_iterations * 0.9:\n                # Local refinement with reduced momentum\n                dx = np.random.normal(0, step_scale * 0.3)\n                dy = np.random.normal(0, step_scale * 0.3)\n            else:\n                # Very local fine-tuning\n                dx = np.random.normal(0, step_scale * 0.1)\n                dy = np.random.normal(0, step_scale * 0.1)\n            \n            new_x = np.clip(x + dx, bounds[0], bounds[1])\n            new_y = np.clip(y + dy, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n            \n            # Accept or reject based on enhanced simulated annealing\n            if new_value < current_value:\n                # Always accept better solutions and update momentum\n                x, y = new_x, new_y\n                current_value = new_value\n                momentum_x = dx * 0.5\n                momentum_y = dy * 0.5\n            else:\n                # Enhanced acceptance for escaping local minima\n                delta = new_value - current_value\n                # Adaptive acceptance probability based on search progress\n                acceptance_boost = 1.0 + (restart_iterations - i) / restart_iterations\n                prob = np.exp(-delta / (temp * acceptance_boost))\n                if np.random.random() < prob:\n                    x, y = new_x, new_y\n                    current_value = new_value\n                    # Reduce momentum on uphill moves\n                    momentum_x *= 0.3\n                    momentum_y *= 0.3\n            \n            # Update best for this restart\n            if current_value < best_restart_value:\n                best_restart_value = current_value\n                best_restart_x, best_restart_y = x, y\n                # Reset stagnation counter when improvement found\n                stagnation_counter = 0\n            else:\n                stagnation_counter += 1\n            \n            # Cool down temperature\n            temp *= temp_decay\n            \n            # Early restart if stuck in local minimum\n            if stagnation_counter > restart_iterations // 4 and i < restart_iterations * 0.8:\n                break\n        \n        # Update global best\n        if best_restart_value < best_global_value:\n            best_global_value = best_restart_value\n            best_global_x, best_global_y = best_restart_x, best_restart_y\n    \n    # Final local refinement around the best solution\n    refinement_iterations = iterations // 10\n    x, y = best_global_x, best_global_y\n    best_value = best_global_value\n    \n    for i in range(refinement_iterations):\n        # Very small steps for fine-tuning\n        step_size = 0.01 * (1 - i/refinement_iterations)\n        dx = np.random.normal(0, step_size)\n        dy = np.random.normal(0, step_size)\n        \n        new_x = np.clip(x + dx, bounds[0], bounds[1])\n        new_y = np.clip(y + dy, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n        \n        if new_value < best_value:\n            x, y, best_value = new_x, new_y, new_value\n    \n    return x, y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Alternative runs_successfully approach, Alternative combined_score approach, NumPy-based implementation\n\n### Inspiration 3 (Score: 1.4962, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid simulated annealing with local refinement to escape local minima.\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multiple restarts from different starting points\n    num_restarts = 5\n    restart_iterations = iterations // num_restarts\n    \n    best_global_x = np.random.uniform(bounds[0], bounds[1])\n    best_global_y = np.random.uniform(bounds[0], bounds[1])\n    best_global_value = evaluate_function(best_global_x, best_global_y)\n    \n    for restart in range(num_restarts):\n        # Initialize restart point\n        if restart == 0:\n            x, y = best_global_x, best_global_y\n        else:\n            x = np.random.uniform(bounds[0], bounds[1])\n            y = np.random.uniform(bounds[0], bounds[1])\n        \n        current_value = evaluate_function(x, y)\n        best_restart_value = current_value\n        best_restart_x, best_restart_y = x, y\n        \n        # Initial temperature for simulated annealing\n        temp = 2.0\n        temp_decay = 0.95\n        \n        for i in range(restart_iterations):\n            # Adaptive step size based on iteration progress\n            step_scale = max(0.1, 2.0 * (1 - i/restart_iterations))\n            \n            # Generate candidate with local search bias\n            if i < restart_iterations * 0.7:\n                # Global exploration with simulated annealing\n                dx = np.random.normal(0, step_scale)\n                dy = np.random.normal(0, step_scale)\n            else:\n                # Local refinement around best point\n                dx = np.random.normal(0, step_scale * 0.3)\n                dy = np.random.normal(0, step_scale * 0.3)\n            \n            new_x = np.clip(x + dx, bounds[0], bounds[1])\n            new_y = np.clip(y + dy, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n            \n            # Accept or reject based on simulated annealing\n            if new_value < current_value:\n                # Always accept better solutions\n                x, y = new_x, new_y\n                current_value = new_value\n            else:\n                # Sometimes accept worse solutions to escape local minima\n                delta = new_value - current_value\n                prob = np.exp(-delta / temp)\n                if np.random.random() < prob:\n                    x, y = new_x, new_y\n                    current_value = new_value\n            \n            # Update best for this restart\n            if current_value < best_restart_value:\n                best_restart_value = current_value\n                best_restart_x, best_restart_y = x, y\n            \n            # Cool down temperature\n            temp *= temp_decay\n        \n        # Update global best\n        if best_restart_value < best_global_value:\n            best_global_value = best_restart_value\n            best_global_x, best_global_y = best_restart_x, best_restart_y\n    \n    return best_global_x, best_global_y, best_global_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Modification: Change 1: Replace 27 lines with 80 lines, Excellent runs_successfully (1.000), Excellent value_score (1.000)\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid optimization algorithm combining simulated annealing with local search.\n    Escapes local minima through temperature-based acceptance and adaptive step sizes.\n    \"\"\"\n    # Initialize with multiple starting points for better coverage\n    num_starts = 5\n    best_results = []\n    \n    for start in range(num_starts):\n        # Simulated annealing parameters\n        temp = 1.0\n        cooling_rate = 0.995\n        \n        # Initialize current point\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(x, y)\n        \n        best_x, best_y, best_value = x, y, current_value\n        \n        # Adaptive step size based on bounds\n        step_size = (bounds[1] - bounds[0]) * 0.1\n        \n        for i in range(iterations // num_starts):\n            # Generate candidate with adaptive step size\n            angle = np.random.uniform(0, 2 * np.pi)\n            step = step_size * (1 - i / (iterations // num_starts))  # Decrease step size\n            candidate_x = x + step * np.cos(angle)\n            candidate_y = y + step * np.sin(angle)\n            \n            # Ensure bounds\n            candidate_x = np.clip(candidate_x, bounds[0], bounds[1])\n            candidate_y = np.clip(candidate_y, bounds[0], bounds[1])\n            \n            candidate_value = evaluate_function(candidate_x, candidate_y)\n            \n            # Accept if better, or with temperature-based probability\n            if candidate_value < current_value:\n                x, y, current_value = candidate_x, candidate_y, candidate_value\n                if candidate_value < best_value:\n                    best_x, best_y, best_value = candidate_x, candidate_y, candidate_value\n            else:\n                # Accept worse solutions with decreasing probability\n                delta = candidate_value - current_value\n                prob = np.exp(-delta / temp)\n                if np.random.random() < prob:\n                    x, y, current_value = candidate_x, candidate_y, candidate_value\n            \n            # Cool down temperature\n            temp *= cooling_rate\n        \n        best_results.append((best_x, best_y, best_value))\n    \n    # Return the best result from all starts\n    return min(best_results, key=lambda x: x[2])\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the program evolution history, I can see that the current implementation has a fitness score of 1.3441, which is a decline from the previous high of 1.4962. The main issues appear to be:\n\n1. The current approach uses polar coordinate-based search (angle + step) which may not be optimal for this function landscape\n2. The cooling schedule and step size adaptation could be improved\n3. The algorithm lacks momentum-based movement and adaptive acceptance strategies\n\nLet me implement several targeted improvements:\n\n## Improvement 1: Replace polar coordinates with momentum-based Gaussian perturbations\n\nThe polar coordinate approach (angle + step) is limiting. Gaussian perturbations with momentum will better navigate the complex landscape.\n\n```python\n<<<<<<< SEARCH\n        for i in range(iterations // num_starts):\n            # Generate candidate with adaptive step size\n            angle = np.random.uniform(0, 2 * np.pi)\n            step = step_size * (1 - i / (iterations // num_starts))  # Decrease step size\n            candidate_x = x + step * np.cos(angle)\n            candidate_y = y + step * np.sin(angle)\n=======\n        # Initialize momentum\n        momentum_x, momentum_y = 0, 0\n        \n        for i in range(iterations // num_starts):\n            # Adaptive step size based on iteration progress and temperature\n            progress = i / (iterations // num_starts)\n            temp_ratio = temp  # Temperature affects step size\n            current_step_size = step_size * (1 - progress) * temp_ratio\n            \n            # Generate candidate with momentum and Gaussian perturbation\n            random_dx = np.random.normal(0, current_step_size)\n            random_dy = np.random.normal(0, current_step_size)\n            \n            # Combine momentum with random walk (momentum helps escape local minima)\n            dx = 0.3 * momentum_x + 0.7 * random_dx\n            dy = 0.3 * momentum_y + 0.7 * random_dy\n            \n            candidate_x = x + dx\n            candidate_y = y + dy\n>>>>>>> REPLACE\n```\n\n## Improvement 2: Enhanced temperature and acceptance strategy\n\nThe current acceptance probability is too simple. We need adaptive acceptance that considers search progress.\n\n```python\n<<<<<<< SEARCH\n            # Accept if better, or with temperature-based probability\n            if candidate_value < current_value:\n                x, y, current_value = candidate_x, candidate_y, candidate_value\n                if candidate_value < best_value:\n                    best_x, best_y, best_value = candidate_x, candidate_y, candidate_value\n            else:\n                # Accept worse solutions with decreasing probability\n                delta = candidate_value - current_value\n                prob = np.exp(-delta / temp)\n                if np.random.random() < prob:\n                    x, y, current_value = candidate_x, candidate_y, candidate_value\n=======\n            # Accept if better, or with enhanced temperature-based probability\n            if candidate_value < current_value:\n                x, y, current_value = candidate_x, candidate_y, candidate_value\n                if candidate_value < best_value:\n                    best_x, best_y, best_value = candidate_x, candidate_y, candidate_value\n                # Update momentum in direction of improvement\n                momentum_x = dx * 0.5\n                momentum_y = dy * 0.5\n            else:\n                # Enhanced acceptance for escaping local minima\n                delta = candidate_value - current_value\n                # Adaptive acceptance based on search progress and temperature\n                progress_factor = 1.0 + (iterations // num_starts - i) / (iterations // num_starts)\n                acceptance_prob = np.exp(-delta / (temp * progress_factor))\n                \n                if np.random.random() < acceptance_prob:\n                    x, y, current_value = candidate_x, candidate_y, candidate_value\n                    # Reduce momentum on uphill moves but don't zero it\n                    momentum_x *= 0.3\n                    momentum_y *= 0.3\n                else:\n                    # Decay momentum when move is rejected\n                    momentum_x *= 0.8\n                    momentum_y *= 0.8\n>>>>>>> REPLACE\n```\n\n## Improvement 3: Better cooling schedule and restart strategy\n\nThe current cooling rate is fixed. We need adaptive cooling and better restart logic.\n\n```python\n<<<<<<< SEARCH\n        # Simulated annealing parameters\n        temp = 1.0\n        cooling_rate = 0.995\n=======\n        # Enhanced simulated annealing parameters\n        temp = 2.0  # Higher initial temperature for better exploration\n        initial_temp = temp\n        # Adaptive cooling: faster cooling when temperature is high, slower when low\n        base_cooling = 0.995\n        # Also add occasional reheating to escape deep local minima\n        reheat_frequency = iterations // (num_starts * 4)\n>>>>>>> REPLACE\n```\n\n```python\n<<<<<<< SEARCH\n            # Cool down temperature\n            temp *= cooling_rate\n=======\n            # Adaptive cooling based on temperature level\n            if temp > initial_temp * 0.5:\n                temp *= base_cooling  # Normal cooling\n            else:\n                temp *= (base_cooling + 0.002)  # Slower cooling at low temperatures\n            \n            # Occasional reheating to escape deep local minima\n            if i % reheat_frequency == 0 and i > 0 and temp < initial_temp * 0.1:\n                temp = min(temp * 2.0, initial_temp * 0.3)\n>>>>>>> REPLACE\n```\n\n## Improvement 4: Add final local refinement phase\n\nThe current algorithm ends abruptly. Adding a final refinement phase will help converge to the exact minimum.\n\n```python\n<<<<<<< SEARCH\n    # Return the best result from all starts\n    return min(best_results, key=lambda x: x[2])\n=======\n    # Get the best result from all starts\n    best_x, best_y, best_value = min(best_results, key=lambda x: x[2])\n    \n    # Final local refinement phase\n    refinement_steps = iterations // 20\n    refinement_step_size = (bounds[1] - bounds[0]) * 0.005\n    \n    for i in range(refinement_steps):\n        # Very small Gaussian perturbations for fine-tuning\n        dx = np.random.normal(0, refinement_step_size * (1 - i/refinement_steps))\n        dy = np.random.normal(0, refinement_step_size * (1 - i/refinement_steps))\n        \n        new_x = np.clip(best_x + dx, bounds[0], bounds[1])\n        new_y = np.clip(best_y + dy, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n        \n        if new_value < best_value:\n            best_x, best_y, best_value = new_x, new_y, new_value\n    \n    return best_x, best_y, best_value\n>>>>>>> REPLACE\n```\n\nThese improvements address the key weaknesses in the current algorithm:\n\n1. **Momentum-based search**: Helps escape local minima by maintaining direction of previous successful moves\n2. **Enhanced acceptance strategy**: Better probability calculation that considers search progress\n3. **Adaptive cooling**: More sophisticated temperature schedule with occasional reheating\n4. **Final refinement**: Ensures convergence to the exact minimum\n\nThe combination of these improvements should significantly boost the fitness score by providing better exploration of the search space while maintaining the ability to escape local minima."]}}, "artifacts_json": "{\"stage1_result\": \"Found solution at x=-1.7064, y=0.6789 with value=-1.5187\", \"distance_to_global\": \"0.0026\", \"solution_quality\": \"Distance < 0.5: Very close\", \"convergence_info\": \"Converged in 10 trials with 10 successes\", \"best_position\": \"Final position: x=-1.7032, y=0.6772\", \"average_distance_to_global\": \"0.0024\", \"search_efficiency\": \"Success rate: 100.00%\"}", "artifact_dir": null, "embedding": null}