{"id": "db52f80a-ff30-4855-afe1-3169884f1b53", "code": "# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid optimization algorithm combining simulated annealing with local search.\n    Escapes local minima through temperature-based acceptance and adaptive step sizes.\n    \"\"\"\n    # Initialize with multiple starting points for better coverage\n    num_starts = 5\n    best_results = []\n    global_best_value = float('inf')\n    promising_regions = []\n    \n    for start in range(num_starts):\n        # Simulated annealing parameters with adaptive cooling and reheating\n        initial_temp = 3.0\n        final_temp = 0.005\n        temp = initial_temp\n        reheat_counter = 0\n        \n        # Initialize current point\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(x, y)\n        \n        best_x, best_y, best_value = x, y, current_value\n        \n        # Adaptive step size based on bounds\n        step_size = (bounds[1] - bounds[0]) * 0.08\n        momentum_x, momentum_y = 0, 0\n        \n        for i in range(iterations // num_starts):\n            # Intelligent restart based on global information\n            if i > 0 and i % (iterations // (num_starts * 4)) == 0:\n                # 40% chance to restart near promising regions or globally\n                if np.random.random() < 0.4:\n                    if len(promising_regions) > 0 and np.random.random() < 0.7:\n                        # Restart near a promising region\n                        region = promising_regions[np.random.randint(len(promising_regions))]\n                        x = region[0] + np.random.normal(0, 0.5)\n                        y = region[1] + np.random.normal(0, 0.5)\n                    else:\n                        # Global restart\n                        x = np.random.uniform(bounds[0], bounds[1])\n                        y = np.random.uniform(bounds[0], bounds[1])\n                    \n                    x = np.clip(x, bounds[0], bounds[1])\n                    y = np.clip(y, bounds[0], bounds[1])\n                    current_value = evaluate_function(x, y)\n                    if current_value < best_value:\n                        best_x, best_y, best_value = x, y, current_value\n                    # Reset momentum for fresh start\n                    momentum_x, momentum_y = 0, 0\n            # Generate candidate with momentum and adaptive perturbations\n            progress = i / (iterations // num_starts)\n            step_scale = step_size * (1 - progress) * (0.7 + 0.3 * temp / initial_temp)\n            \n            # Add momentum to escape local minima more effectively\n            random_dx = np.random.normal(0, step_scale)\n            random_dy = np.random.normal(0, step_scale)\n            dx = 0.2 * momentum_x + 0.8 * random_dx\n            dy = 0.2 * momentum_y + 0.8 * random_dy\n            \n            candidate_x = x + dx\n            candidate_y = y + dy\n            \n            # Ensure bounds\n            candidate_x = np.clip(candidate_x, bounds[0], bounds[1])\n            candidate_y = np.clip(candidate_y, bounds[0], bounds[1])\n            \n            candidate_value = evaluate_function(candidate_x, candidate_y)\n            \n            # Accept if better, or with temperature-based probability\n            if candidate_value < current_value:\n                x, y, current_value = candidate_x, candidate_y, candidate_value\n                if candidate_value < best_value:\n                    best_x, best_y, best_value = candidate_x, candidate_y, candidate_value\n                # Update momentum in direction of improvement\n                momentum_x = dx * 0.3\n                momentum_y = dy * 0.3\n                reheat_counter = 0  # Reset stagnation counter\n            else:\n                # Accept worse solutions with decreasing probability\n                delta = candidate_value - current_value\n                prob = np.exp(-delta / temp)\n                if np.random.random() < prob:\n                    x, y, current_value = candidate_x, candidate_y, candidate_value\n                    # Reduce momentum on uphill moves\n                    momentum_x *= 0.2\n                    momentum_y *= 0.2\n                else:\n                    # Decay momentum when move is rejected\n                    momentum_x *= 0.7\n                    momentum_y *= 0.7\n                    reheat_counter += 1\n            \n            # Enhanced temperature schedule with adaptive cooling\n            progress = i / (iterations // num_starts)\n            base_temp = initial_temp * (1 - progress) + final_temp * progress\n            \n            # Adaptive temperature based on improvement rate\n            if reheat_counter > 30:\n                # Stuck in local minimum - reheat more aggressively\n                temp = min(base_temp * 3.0, initial_temp * 0.6)\n                reheat_counter = 0\n            elif best_value < global_best_value:\n                # Found global improvement - cool faster to refine\n                temp = base_temp * 0.8\n                global_best_value = best_value\n            else:\n                temp = base_temp\n            \n            # Store promising regions for cooperative search\n            if i % 20 == 0 and best_value < -1.0:\n                promising_regions.append((best_x, best_y))\n                # Keep only top promising regions\n                if len(promising_regions) > 3:\n                    promising_regions.pop(0)\n        \n        best_results.append((best_x, best_y, best_value))\n    \n    # Enhanced final refinement with multi-scale approach\n    if len(best_results) > 0:\n        best_current = min(best_results, key=lambda x: x[2])\n        \n        # Multi-scale refinement: from coarse to fine\n        scales = [0.05, 0.02, 0.008, 0.003]\n        for scale in scales:\n            for _ in range(12):\n                # Try multiple perturbation types\n                if np.random.random() < 0.6:\n                    # Gaussian perturbation\n                    dx = np.random.normal(0, scale)\n                    dy = np.random.normal(0, scale)\n                else:\n                    # Uniform perturbation for better coverage\n                    dx = np.random.uniform(-scale, scale)\n                    dy = np.random.uniform(-scale, scale)\n                \n                local_candidate_x = best_current[0] + dx\n                local_candidate_y = best_current[1] + dy\n                local_candidate_x = np.clip(local_candidate_x, bounds[0], bounds[1])\n                local_candidate_y = np.clip(local_candidate_y, bounds[0], bounds[1])\n                local_value = evaluate_function(local_candidate_x, local_candidate_y)\n                if local_value < best_current[2]:\n                    best_results[-1] = (local_candidate_x, local_candidate_y, local_value)\n                    best_current = (local_candidate_x, local_candidate_y, local_value)\n    \n    # Return the best result from all starts\n    return min(best_results, key=lambda x: x[2])\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n", "language": "python", "parent_id": "73df3613-bc99-4fc2-b451-c8105e469d52", "generation": 4, "timestamp": 1765023388.379662, "iteration_found": 44, "metrics": {"runs_successfully": 1.0, "value_score": 0.9994422063912614, "distance_score": 0.9920680361132157, "combined_score": 1.496012271044393, "reliability_score": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 10 lines with 12 lines\nChange 2: Replace 7 lines with 21 lines\nChange 3: Replace 8 lines with 22 lines\nChange 4: Replace 12 lines with 26 lines", "parent_metrics": {"runs_successfully": 1.0, "value_score": 0.9409340468233706, "distance_score": 0.6507849559608206, "combined_score": 1.0388430122399177, "reliability_score": 1.0}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve a function minimization algorithm to find the global minimum of a complex function with many local minima. The function is f(x, y) = sin(x) * cos(y) + sin(x*y) + (x^2 + y^2)/20. Focus on improving the search_algorithm function to reliably find the global minimum, escaping local minima that might trap simple algorithms.", "user": "# Current Program Information\n- Fitness: 1.0388\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness declined: 1.4994 \u2192 1.0388. Consider revising recent changes.\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### stage1_result\n```\nFound solution at x=-1.5888, y=0.7195 with value=-1.5098\n```\n\n### distance_to_global\n```\n0.1225\n```\n\n### solution_quality\n```\nDistance < 0.5: Very close\n```\n\n### convergence_info\n```\nConverged in 10 trials with 10 successes\n```\n\n### best_position\n```\nFinal position: x=-1.7449, y=0.6836\n```\n\n### average_distance_to_global\n```\n0.5366\n```\n\n### search_efficiency\n```\nSuccess rate: 100.00%\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 76 lines with 57 lines\nChange 2: Replace return best_x, best_y, best_value with 14 lines\n- Metrics: runs_successfully: 1.0000, value_score: 0.9997, distance_score: 0.9992, combined_score: 1.4994, reliability_score: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Change 1: Replace 27 lines with 78 lines\n- Metrics: runs_successfully: 1.0000, value_score: 0.9997, distance_score: 0.9995, combined_score: 1.4995, reliability_score: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Change 1: Replace 8 lines with 12 lines\nChange 2: Replace 5 lines with 13 lines\nChange 3: Replace 12 lines with 34 lines\nChange 4: Replace 7 lines with 17 lines\nChange 5: Replace 3 lines with 6 lines\n- Metrics: runs_successfully: 1.0000, value_score: 0.9997, distance_score: 0.9995, combined_score: 1.4995, reliability_score: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.4995)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Efficient hybrid optimization with adaptive cooling and strategic exploration.\n    \"\"\"\n    # Initialize 5 candidates and find initial best\n    candidates = [(np.random.uniform(*bounds), np.random.uniform(*bounds)) for _ in range(5)]\n    values = [evaluate_function(x, y) for x, y in candidates]\n    \n    best_idx = np.argmin(values)\n    best_x, best_y = candidates[best_idx]\n    best_value = values[best_idx]\n    \n    # Enhanced temperature schedule with reheating\n    temp = 10.0\n    initial_temp = temp\n    cooling_rate = 0.002  # Slower cooling for better exploration\n    stagnation_counter = 0\n    last_best = float('inf')\n    \n    for i in range(iterations):\n        # Progress-based step scaling with temperature influence\n        progress = i / iterations\n        temp_ratio = temp / initial_temp\n        step_scale = max(0.05, 1.5 * (1 - progress) * temp_ratio)\n        \n        for j in range(5):\n            x, y = candidates[j]\n            current_value = values[j]\n            \n            # Generate candidate with adaptive noise and momentum\n            # Add small momentum component for more efficient search\n            momentum_factor = 0.2 if i > iterations // 10 else 0.0\n            \n            if i > 0 and hasattr(search_algorithm, '_last_dx'):\n                dx = np.random.normal(0, step_scale) + momentum_factor * search_algorithm._last_dx\n                dy = np.random.normal(0, step_scale) + momentum_factor * search_algorithm._last_dy\n            else:\n                dx = np.random.normal(0, step_scale)\n                dy = np.random.normal(0, step_scale)\n            \n            new_x = np.clip(x + dx, *bounds)\n            new_y = np.clip(y + dy, *bounds)\n            new_value = evaluate_function(new_x, new_y)\n            \n            # Enhanced acceptance criteria\n            delta = new_value - current_value\n            if delta < 0 or (temp > 0.5 and np.random.random() < np.exp(-delta / temp)):\n                # Store momentum for next iteration\n                search_algorithm._last_dx = dx\n                search_algorithm._last_dy = dy\n                candidates[j] = (new_x, new_y)\n                values[j] = new_value\n                \n                if new_value < best_value:\n                    best_value = new_value\n                    best_x, best_y = new_x, new_y\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n        \n        # Intelligent reheating when stagnated\n        if stagnation_counter > iterations // 20 and temp < initial_temp * 0.3:\n            temp = min(temp * 3.0, initial_temp * 0.8)\n            stagnation_counter = 0\n        \n        # Strategic exploration: replace worst with probability\n        if i % max(1, iterations // 10) == 0 and i > 0:\n            if np.random.random() < 0.3:  # 30% chance to explore\n                worst_idx = np.argmax(values)\n                candidates[worst_idx] = (np.random.uniform(*bounds), np.random.uniform(*bounds))\n                values[worst_idx] = evaluate_function(*candidates[worst_idx])\n                \n                if values[worst_idx] < best_value:\n                    best_value = values[worst_idx]\n                    best_x, best_y = candidates[worst_idx]\n        \n        # Adaptive cooling with restart protection\n        temp *= (1 - cooling_rate)\n        if temp < 0.1 and i < iterations * 0.8:  # Prevent premature convergence\n            temp = 0.5\n    \n    # Enhanced multi-scale refinement with adaptive search\n    refinement_budget = min(100, iterations // 10)\n    \n    # Multi-scale approach: coarse to fine\n    scales = [0.1, 0.03, 0.01, 0.003]\n    for scale_idx, base_scale in enumerate(scales):\n        scale_iterations = refinement_budget // len(scales)\n        \n        for i in range(scale_iterations):\n            # Adaptive step size with decay\n            progress = i / scale_iterations\n            step_size = base_scale * (1 - progress * 0.7)\n            \n            # Generate multiple candidates in a small neighborhood\n            for attempt in range(5):\n                # Use both Gaussian and uniform perturbations\n                if attempt < 3:\n                    # Gaussian perturbation\n                    dx = np.random.normal(0, step_size)\n                    dy = np.random.normal(0, step_size)\n                else:\n                    # Uniform perturbation for diversity\n                    dx = np.random.uniform(-step_size, step_size)\n                    dy = np.random.uniform(-step_size, step_size)\n                \n                new_x = np.clip(best_x + dx, *bounds)\n                new_y = np.clip(best_y + dy, *bounds)\n                new_value = evaluate_function(new_x, new_y)\n                \n                if new_value < best_value:\n                    best_value = new_value\n                    best_x, best_y = new_x, new_y\n                    # Found improvement, can be more aggressive\n                    break\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9997), Performs well on distance_score (0.9995), Performs well on combined_score (1.4995), Performs well on reliability_score (1.0000)\n\n### Program 2 (Score: 1.4995)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Adaptive differential evolution with local search hybrid.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Population size\n    pop_size = 20\n    \n    # Initialize population\n    population = np.random.uniform(bounds[0], bounds[1], (pop_size, 2))\n    values = np.array([evaluate_function(x, y) for x, y in population])\n    \n    # Track best solution\n    best_idx = np.argmin(values)\n    best_x, best_y = population[best_idx]\n    best_value = values[best_idx]\n    \n    # Adaptive parameters\n    mutation_factor = 0.8\n    crossover_prob = 0.7\n    \n    for i in range(iterations):\n        # Adaptive parameters based on progress\n        progress = i / iterations\n        mutation_factor = 0.5 + 0.3 * (1 - progress)\n        crossover_prob = 0.5 + 0.2 * (1 - progress)\n        \n        for j in range(pop_size):\n            # Select three random individuals (different from j)\n            candidates = list(range(pop_size))\n            candidates.remove(j)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Differential mutation\n            mutant = population[a] + mutation_factor * (population[b] - population[c])\n            \n            # Crossover\n            trial = population[j].copy()\n            crossover_mask = np.random.random(2) < crossover_prob\n            trial[crossover_mask] = mutant[crossover_mask]\n            \n            # Ensure bounds\n            trial = np.clip(trial, bounds[0], bounds[1])\n            \n            # Evaluate trial\n            trial_value = evaluate_function(trial[0], trial[1])\n            \n            # Selection\n            if trial_value < values[j]:\n                population[j] = trial\n                values[j] = trial_value\n                \n                # Update global best\n                if trial_value < best_value:\n                    best_x, best_y = trial[0], trial[1]\n                    best_value = trial_value\n        \n        # Periodic local search around best solution\n        if i % 50 == 0 and i > 0:\n            local_step = 0.1 * (1 - progress)\n            for _ in range(10):\n                local_x = best_x + np.random.normal(0, local_step)\n                local_y = best_y + np.random.normal(0, local_step)\n                local_x = np.clip(local_x, bounds[0], bounds[1])\n                local_y = np.clip(local_y, bounds[0], bounds[1])\n                local_value = evaluate_function(local_x, local_y)\n                \n                if local_value < best_value:\n                    best_x, best_y = local_x, local_y\n                    best_value = local_value\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9997), Performs well on distance_score (0.9995), Performs well on combined_score (1.4995), Performs well on reliability_score (1.0000)\n\n### Program 3 (Score: 1.4994)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Efficient hybrid optimization with adaptive cooling and strategic exploration.\n    \"\"\"\n    # Initialize 5 candidates and find initial best\n    candidates = [(np.random.uniform(*bounds), np.random.uniform(*bounds)) for _ in range(5)]\n    values = [evaluate_function(x, y) for x, y in candidates]\n    \n    best_idx = np.argmin(values)\n    best_x, best_y = candidates[best_idx]\n    best_value = values[best_idx]\n    \n    # Adaptive temperature schedule\n    temp = 10.0\n    cooling_rate = 0.003  # More aggressive cooling\n    \n    for i in range(iterations):\n        # Progress-based step scaling\n        progress = i / iterations\n        step_scale = max(0.05, 1.5 * (1 - progress) * (temp / 10.0))\n        \n        for j in range(5):\n            x, y = candidates[j]\n            current_value = values[j]\n            \n            # Generate candidate with adaptive noise\n            new_x = np.clip(x + np.random.normal(0, step_scale), *bounds)\n            new_y = np.clip(y + np.random.normal(0, step_scale), *bounds)\n            new_value = evaluate_function(new_x, new_y)\n            \n            # Enhanced acceptance criteria\n            delta = new_value - current_value\n            if delta < 0 or (temp > 0.5 and np.random.random() < np.exp(-delta / temp)):\n                candidates[j] = (new_x, new_y)\n                values[j] = new_value\n                \n                if new_value < best_value:\n                    best_value = new_value\n                    best_x, best_y = new_x, new_y\n        \n        # Strategic exploration: replace worst with probability\n        if i % max(1, iterations // 10) == 0 and i > 0:\n            if np.random.random() < 0.3:  # 30% chance to explore\n                worst_idx = np.argmax(values)\n                candidates[worst_idx] = (np.random.uniform(*bounds), np.random.uniform(*bounds))\n                values[worst_idx] = evaluate_function(*candidates[worst_idx])\n                \n                if values[worst_idx] < best_value:\n                    best_value = values[worst_idx]\n                    best_x, best_y = candidates[worst_idx]\n        \n        # Adaptive cooling with restart protection\n        temp *= (1 - cooling_rate)\n        if temp < 0.1 and i < iterations * 0.8:  # Prevent premature convergence\n            temp = 0.5\n    \n    # Final focused refinement around best solution\n    refinement_steps = min(50, iterations // 20)\n    for i in range(refinement_steps):\n        step_size = 0.02 * (1 - i/refinement_steps)\n        for _ in range(3):  # Multiple tries per step\n            new_x = np.clip(best_x + np.random.normal(0, step_size), *bounds)\n            new_y = np.clip(best_y + np.random.normal(0, step_size), *bounds)\n            new_value = evaluate_function(new_x, new_y)\n            \n            if new_value < best_value:\n                best_value = new_value\n                best_x, best_y = new_x, new_y\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9997), Performs well on distance_score (0.9992), Performs well on combined_score (1.4994), Performs well on reliability_score (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 1.4987)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid optimization algorithm combining simulated annealing with local search.\n    Escapes local minima through temperature-based acceptance and adaptive step sizes.\n    \"\"\"\n    # Initialize with multiple starting points for better coverage\n    num_starts = 5\n    best_results = []\n    \n    for start in range(num_starts):\n        # Enhanced simulated annealing parameters\n        temp = 2.0  # Higher initial temperature for better exploration\n        initial_temp = temp\n        # Adaptive cooling: faster cooling when temperature is high, slower when low\n        base_cooling = 0.995\n        # Also add occasional reheating to escape deep local minima\n        reheat_frequency = iterations // (num_starts * 4)\n        \n        # Initialize current point\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(x, y)\n        \n        best_x, best_y, best_value = x, y, current_value\n        \n        # Adaptive step size based on bounds\n        step_size = (bounds[1] - bounds[0]) * 0.1\n        \n        # Initialize momentum\n        momentum_x, momentum_y = 0, 0\n        \n        for i in range(iterations // num_starts):\n            # Adaptive step size based on iteration progress and temperature\n            progress = i / (iterations // num_starts)\n            temp_ratio = temp  # Temperature affects step size\n            current_step_size = step_size * (1 - progress) * temp_ratio\n            \n            # Generate candidate with momentum and Gaussian perturbation\n            random_dx = np.random.normal(0, current_step_size)\n            random_dy = np.random.normal(0, current_step_size)\n            \n            # Combine momentum with random walk (momentum helps escape local minima)\n            dx = 0.3 * momentum_x + 0.7 * random_dx\n            dy = 0.3 * momentum_y + 0.7 * random_dy\n            \n            candidate_x = x + dx\n            candidate_y = y + dy\n            \n            # Ensure bounds\n            candidate_x = np.clip(candidate_x, bounds[0], bounds[1])\n            candidate_y = np.clip(candidate_y, bounds[0], bounds[1])\n            \n            candidate_value = evaluate_function(candidate_x, candidate_y)\n            \n            # Accept if better, or with enhanced temperature-based probability\n            if candidate_value < current_value:\n                x, y, current_value = candidate_x, candidate_y, candidate_value\n                if candidate_value < best_value:\n                    best_x, best_y, best_value = candidate_x, candidate_y, candidate_value\n                # Update momentum in direction of improvement\n                momentum_x = dx * 0.5\n                momentum_y = dy * 0.5\n            else:\n                # Enhanced acceptance for escaping local minima\n                delta = candidate_value - current_value\n                # Adaptive acceptance based on search progress and temperature\n                progress_factor = 1.0 + (iterations // num_starts - i) / (iterations // num_starts)\n                acceptance_prob = np.exp(-delta / (temp * progress_factor))\n                \n                if np.random.random() < acceptance_prob:\n                    x, y, current_value = candidate_x, candidate_y, candidate_value\n                    # Reduce momentum on uphill moves but don't zero it\n                    momentum_x *= 0.3\n                    momentum_y *= 0.3\n                else:\n                    # Decay momentum when move is rejected\n                    momentum_x *= 0.8\n                    momentum_y *= 0.8\n            \n            # Adaptive cooling based on temperature level\n            if temp > initial_temp * 0.5:\n                temp *= base_cooling  # Normal cooling\n            else:\n                temp *= (base_cooling + 0.002)  # Slower cooling at low temperatures\n            \n            # Occasional reheating to escape deep local minima\n            if i % reheat_frequency == 0 and i > 0 and temp < initial_temp * 0.1:\n                temp = min(temp * 2.0, initial_temp * 0.3)\n        \n        best_results.append((best_x, best_y, best_value))\n    \n    # Get the best result from all starts\n    best_x, best_y, best_value = min(best_results, key=lambda x: x[2])\n    \n    # Final local refinement phase\n    refinement_steps = iterations // 20\n    refinement_step_size = (bounds[1] - bounds[0]) * 0.005\n    \n    for i in range(refinement_steps):\n        # Very small Gaussian perturbations for fine-tuning\n        dx = np.random.normal(0, refinement_step_size * (1 - i/refinement_steps))\n        dy = np.random.normal(0, refinement_step_size * (1 - i/refinement_steps))\n        \n        new_x = np.clip(best_x + dx, bounds[0], bounds[1])\n        new_y = np.clip(best_y + dy, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n        \n        if new_value < best_value:\n            best_x, best_y, best_value = new_x, new_y, new_value\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to value_score\n\n### Program D2 (Score: 1.4967)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Advanced hybrid search combining simulated annealing, local search, and multi-start strategy.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n    \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start with 5 candidates for better coverage (increased from 3)\n    candidates = []\n    for _ in range(5):\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        value = evaluate_function(x, y)\n        candidates.append((x, y, value))\n    \n    # Simulated annealing parameters with better cooling schedule\n    initial_temp = 10.0\n    final_temp = 0.01\n    cooling_rate = (final_temp / initial_temp) ** (1.0 / iterations)\n    temperature = initial_temp\n    \n    # Track global best for better convergence\n    best_idx = min(range(5), key=lambda i: candidates[i][2])\n    best_x, best_y, best_value = candidates[best_idx]\n    \n    for i in range(iterations):\n        # Update temperature with exponential cooling\n        temperature *= cooling_rate\n        \n        for j, (x, y, current_value) in enumerate(candidates):\n            # Adaptive step size based on iteration progress\n            if i < iterations // 3:\n                # Early exploration: larger steps\n                step_scale = 2.0 * (1 - i/iterations)\n            else:\n                # Late refinement: smaller steps focused around best\n                step_scale = max(0.1, 0.5 * (1 - i/iterations))\n            \n            # Local perturbation with Gaussian noise\n            new_x = x + np.random.normal(0, step_scale)\n            new_y = y + np.random.normal(0, step_scale)\n            \n            # Keep within bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            \n            new_value = evaluate_function(new_x, new_y)\n            \n            # Accept if better, or with probability if worse (simulated annealing)\n            delta = new_value - current_value\n            if delta < 0 or (temperature > 0.1 and np.random.random() < np.exp(-delta / temperature)):\n                candidates[j] = (new_x, new_y, new_value)\n                \n                # Update global best when we find a better solution\n                if new_value < best_value:\n                    best_value = new_value\n                    best_x, best_y = new_x, new_y\n        \n        # Strategic long-range exploration: replace worst candidate\n        if i % (iterations // 8) == 0 and i > 0:\n            worst_idx = max(range(5), key=lambda i: candidates[i][2])\n            x = np.random.uniform(bounds[0], bounds[1])\n            y = np.random.uniform(bounds[0], bounds[1])\n            value = evaluate_function(x, y)\n            candidates[worst_idx] = (x, y, value)\n            \n            # Update global best if needed\n            if value < best_value:\n                best_value = value\n                best_x, best_y = x, y\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to value_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 1.4987, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid optimization algorithm combining simulated annealing with local search.\n    Escapes local minima through temperature-based acceptance and adaptive step sizes.\n    \"\"\"\n    # Initialize with multiple starting points for better coverage\n    num_starts = 5\n    best_results = []\n    \n    for start in range(num_starts):\n        # Enhanced simulated annealing parameters\n        temp = 2.0  # Higher initial temperature for better exploration\n        initial_temp = temp\n        # Adaptive cooling: faster cooling when temperature is high, slower when low\n        base_cooling = 0.995\n        # Also add occasional reheating to escape deep local minima\n        reheat_frequency = iterations // (num_starts * 4)\n        \n        # Initialize current point\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(x, y)\n        \n        best_x, best_y, best_value = x, y, current_value\n        \n        # Adaptive step size based on bounds\n        step_size = (bounds[1] - bounds[0]) * 0.1\n        \n        # Initialize momentum\n        momentum_x, momentum_y = 0, 0\n        \n        for i in range(iterations // num_starts):\n            # Adaptive step size based on iteration progress and temperature\n            progress = i / (iterations // num_starts)\n            temp_ratio = temp  # Temperature affects step size\n            current_step_size = step_size * (1 - progress) * temp_ratio\n            \n            # Generate candidate with momentum and Gaussian perturbation\n            random_dx = np.random.normal(0, current_step_size)\n            random_dy = np.random.normal(0, current_step_size)\n            \n            # Combine momentum with random walk (momentum helps escape local minima)\n            dx = 0.3 * momentum_x + 0.7 * random_dx\n            dy = 0.3 * momentum_y + 0.7 * random_dy\n            \n            candidate_x = x + dx\n            candidate_y = y + dy\n            \n            # Ensure bounds\n            candidate_x = np.clip(candidate_x, bounds[0], bounds[1])\n            candidate_y = np.clip(candidate_y, bounds[0], bounds[1])\n            \n            candidate_value = evaluate_function(candidate_x, candidate_y)\n            \n            # Accept if better, or with enhanced temperature-based probability\n            if candidate_value < current_value:\n                x, y, current_value = candidate_x, candidate_y, candidate_value\n                if candidate_value < best_value:\n                    best_x, best_y, best_value = candidate_x, candidate_y, candidate_value\n                # Update momentum in direction of improvement\n                momentum_x = dx * 0.5\n                momentum_y = dy * 0.5\n            else:\n                # Enhanced acceptance for escaping local minima\n                delta = candidate_value - current_value\n                # Adaptive acceptance based on search progress and temperature\n                progress_factor = 1.0 + (iterations // num_starts - i) / (iterations // num_starts)\n                acceptance_prob = np.exp(-delta / (temp * progress_factor))\n                \n                if np.random.random() < acceptance_prob:\n                    x, y, current_value = candidate_x, candidate_y, candidate_value\n                    # Reduce momentum on uphill moves but don't zero it\n                    momentum_x *= 0.3\n                    momentum_y *= 0.3\n                else:\n                    # Decay momentum when move is rejected\n                    momentum_x *= 0.8\n                    momentum_y *= 0.8\n            \n            # Adaptive cooling based on temperature level\n            if temp > initial_temp * 0.5:\n                temp *= base_cooling  # Normal cooling\n            else:\n                temp *= (base_cooling + 0.002)  # Slower cooling at low temperatures\n            \n            # Occasional reheating to escape deep local minima\n            if i % reheat_frequency == 0 and i > 0 and temp < initial_temp * 0.1:\n                temp = min(temp * 2.0, initial_temp * 0.3)\n        \n        best_results.append((best_x, best_y, best_value))\n    \n    # Get the best result from all starts\n    best_x, best_y, best_value = min(best_results, key=lambda x: x[2])\n    \n    # Final local refinement phase\n    refinement_steps = iterations // 20\n    refinement_step_size = (bounds[1] - bounds[0]) * 0.005\n    \n    for i in range(refinement_steps):\n        # Very small Gaussian perturbations for fine-tuning\n        dx = np.random.normal(0, refinement_step_size * (1 - i/refinement_steps))\n        dy = np.random.normal(0, refinement_step_size * (1 - i/refinement_steps))\n        \n        new_x = np.clip(best_x + dx, bounds[0], bounds[1])\n        new_y = np.clip(best_y + dy, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n        \n        if new_value < best_value:\n            best_x, best_y, best_value = new_x, new_y, new_value\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Excellent runs_successfully (1.000), Excellent value_score (1.000), Excellent distance_score (0.998)\n\n### Inspiration 2 (Score: 0.9702, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid optimization algorithm combining simulated annealing with local search.\n    Escapes local minima through temperature-based acceptance and adaptive step sizes.\n    \"\"\"\n    # Initialize with multiple starting points for better coverage\n    num_starts = 5\n    best_results = []\n    \n    for start in range(num_starts):\n        # Simulated annealing parameters with adaptive cooling\n        initial_temp = 2.0\n        final_temp = 0.01\n        temp = initial_temp\n        \n        # Initialize current point\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(x, y)\n        \n        best_x, best_y, best_value = x, y, current_value\n        \n        # Adaptive step size based on bounds\n        step_size = (bounds[1] - bounds[0]) * 0.1\n        \n        for i in range(iterations // num_starts):\n            # Occasional random restart to escape deep local minima\n            if i > 0 and i % (iterations // (num_starts * 5)) == 0 and np.random.random() < 0.3:\n                x = np.random.uniform(bounds[0], bounds[1])\n                y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(x, y)\n                if current_value < best_value:\n                    best_x, best_y, best_value = x, y, current_value\n            # Generate candidate with adaptive Gaussian perturbations\n            step_scale = step_size * (1 - i / (iterations // num_starts))\n            candidate_x = x + np.random.normal(0, step_scale)\n            candidate_y = y + np.random.normal(0, step_scale)\n            \n            # Ensure bounds\n            candidate_x = np.clip(candidate_x, bounds[0], bounds[1])\n            candidate_y = np.clip(candidate_y, bounds[0], bounds[1])\n            \n            candidate_value = evaluate_function(candidate_x, candidate_y)\n            \n            # Accept if better, or with temperature-based probability\n            if candidate_value < current_value:\n                x, y, current_value = candidate_x, candidate_y, candidate_value\n                if candidate_value < best_value:\n                    best_x, best_y, best_value = candidate_x, candidate_y, candidate_value\n            else:\n                # Accept worse solutions with decreasing probability\n                delta = candidate_value - current_value\n                prob = np.exp(-delta / temp)\n                if np.random.random() < prob:\n                    x, y, current_value = candidate_x, candidate_y, candidate_value\n            \n            # Adaptive cooling based on progress\n            progress = i / (iterations // num_starts)\n            temp = initial_temp * (1 - progress) + final_temp * progress\n        \n        best_results.append((best_x, best_y, best_value))\n    \n    # Add local refinement around the best solution found so far\n    if start % 2 == 0 and start > 0:  # Every other restart, do local refinement\n        best_current = min(best_results, key=lambda x: x[2])\n        local_step = 0.05\n        for _ in range(20):\n            local_candidate_x = best_current[0] + np.random.normal(0, local_step)\n            local_candidate_y = best_current[1] + np.random.normal(0, local_step)\n            local_candidate_x = np.clip(local_candidate_x, bounds[0], bounds[1])\n            local_candidate_y = np.clip(local_candidate_y, bounds[0], bounds[1])\n            local_value = evaluate_function(local_candidate_x, local_candidate_y)\n            if local_value < best_current[2]:\n                best_results[-1] = (local_candidate_x, local_candidate_y, local_value)\n    \n    # Return the best result from all starts\n    return min(best_results, key=lambda x: x[2])\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Excellent runs_successfully (1.000), Excellent value_score (0.955), Excellent combined_score (0.970)\n\n### Inspiration 3 (Score: 1.4995, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Adaptive differential evolution with local search hybrid.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Population size\n    pop_size = 20\n    \n    # Initialize population\n    population = np.random.uniform(bounds[0], bounds[1], (pop_size, 2))\n    values = np.array([evaluate_function(x, y) for x, y in population])\n    \n    # Track best solution\n    best_idx = np.argmin(values)\n    best_x, best_y = population[best_idx]\n    best_value = values[best_idx]\n    \n    # Adaptive parameters\n    mutation_factor = 0.8\n    crossover_prob = 0.7\n    \n    for i in range(iterations):\n        # Adaptive parameters based on progress\n        progress = i / iterations\n        mutation_factor = 0.5 + 0.3 * (1 - progress)\n        crossover_prob = 0.5 + 0.2 * (1 - progress)\n        \n        for j in range(pop_size):\n            # Select three random individuals (different from j)\n            candidates = list(range(pop_size))\n            candidates.remove(j)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Differential mutation\n            mutant = population[a] + mutation_factor * (population[b] - population[c])\n            \n            # Crossover\n            trial = population[j].copy()\n            crossover_mask = np.random.random(2) < crossover_prob\n            trial[crossover_mask] = mutant[crossover_mask]\n            \n            # Ensure bounds\n            trial = np.clip(trial, bounds[0], bounds[1])\n            \n            # Evaluate trial\n            trial_value = evaluate_function(trial[0], trial[1])\n            \n            # Selection\n            if trial_value < values[j]:\n                population[j] = trial\n                values[j] = trial_value\n                \n                # Update global best\n                if trial_value < best_value:\n                    best_x, best_y = trial[0], trial[1]\n                    best_value = trial_value\n        \n        # Periodic local search around best solution\n        if i % 50 == 0 and i > 0:\n            local_step = 0.1 * (1 - progress)\n            for _ in range(10):\n                local_x = best_x + np.random.normal(0, local_step)\n                local_y = best_y + np.random.normal(0, local_step)\n                local_x = np.clip(local_x, bounds[0], bounds[1])\n                local_y = np.clip(local_y, bounds[0], bounds[1])\n                local_value = evaluate_function(local_x, local_y)\n                \n                if local_value < best_value:\n                    best_x, best_y = local_x, local_y\n                    best_value = local_value\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Modification: Change 1: Replace 27 lines with 78 lines, Excellent runs_successfully (1.000), Excellent value_score (1.000)\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid optimization algorithm combining simulated annealing with local search.\n    Escapes local minima through temperature-based acceptance and adaptive step sizes.\n    \"\"\"\n    # Initialize with multiple starting points for better coverage\n    num_starts = 5\n    best_results = []\n    \n    for start in range(num_starts):\n        # Simulated annealing parameters with adaptive cooling and reheating\n        initial_temp = 3.0\n        final_temp = 0.005\n        temp = initial_temp\n        reheat_counter = 0\n        \n        # Initialize current point\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(x, y)\n        \n        best_x, best_y, best_value = x, y, current_value\n        \n        # Adaptive step size based on bounds\n        step_size = (bounds[1] - bounds[0]) * 0.08\n        momentum_x, momentum_y = 0, 0\n        \n        for i in range(iterations // num_starts):\n            # Occasional random restart to escape deep local minima\n            if i > 0 and i % (iterations // (num_starts * 5)) == 0 and np.random.random() < 0.3:\n                x = np.random.uniform(bounds[0], bounds[1])\n                y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(x, y)\n                if current_value < best_value:\n                    best_x, best_y, best_value = x, y, current_value\n            # Generate candidate with momentum and adaptive perturbations\n            progress = i / (iterations // num_starts)\n            step_scale = step_size * (1 - progress) * (0.7 + 0.3 * temp / initial_temp)\n            \n            # Add momentum to escape local minima more effectively\n            random_dx = np.random.normal(0, step_scale)\n            random_dy = np.random.normal(0, step_scale)\n            dx = 0.2 * momentum_x + 0.8 * random_dx\n            dy = 0.2 * momentum_y + 0.8 * random_dy\n            \n            candidate_x = x + dx\n            candidate_y = y + dy\n            \n            # Ensure bounds\n            candidate_x = np.clip(candidate_x, bounds[0], bounds[1])\n            candidate_y = np.clip(candidate_y, bounds[0], bounds[1])\n            \n            candidate_value = evaluate_function(candidate_x, candidate_y)\n            \n            # Accept if better, or with temperature-based probability\n            if candidate_value < current_value:\n                x, y, current_value = candidate_x, candidate_y, candidate_value\n                if candidate_value < best_value:\n                    best_x, best_y, best_value = candidate_x, candidate_y, candidate_value\n                # Update momentum in direction of improvement\n                momentum_x = dx * 0.3\n                momentum_y = dy * 0.3\n                reheat_counter = 0  # Reset stagnation counter\n            else:\n                # Accept worse solutions with decreasing probability\n                delta = candidate_value - current_value\n                prob = np.exp(-delta / temp)\n                if np.random.random() < prob:\n                    x, y, current_value = candidate_x, candidate_y, candidate_value\n                    # Reduce momentum on uphill moves\n                    momentum_x *= 0.2\n                    momentum_y *= 0.2\n                else:\n                    # Decay momentum when move is rejected\n                    momentum_x *= 0.7\n                    momentum_y *= 0.7\n                    reheat_counter += 1\n            \n            # Adaptive cooling with occasional reheating\n            progress = i / (iterations // num_starts)\n            temp = initial_temp * (1 - progress) + final_temp * progress\n            \n            # Reheat if stuck in local minimum\n            if reheat_counter > 50 and temp < initial_temp * 0.3:\n                temp = min(temp * 2.0, initial_temp * 0.5)\n                reheat_counter = 0\n        \n        best_results.append((best_x, best_y, best_value))\n    \n    # Local refinement after each restart\n    if len(best_results) > 0:\n        best_current = min(best_results, key=lambda x: x[2])\n        local_step = 0.03 * (1 - start / num_starts)  # Decreasing step size\n        for _ in range(15):\n            local_candidate_x = best_current[0] + np.random.normal(0, local_step)\n            local_candidate_y = best_current[1] + np.random.normal(0, local_step)\n            local_candidate_x = np.clip(local_candidate_x, bounds[0], bounds[1])\n            local_candidate_y = np.clip(local_candidate_y, bounds[0], bounds[1])\n            local_value = evaluate_function(local_candidate_x, local_candidate_y)\n            if local_value < best_current[2]:\n                best_results[-1] = (local_candidate_x, local_candidate_y, local_value)\n    \n    # Return the best result from all starts\n    return min(best_results, key=lambda x: x[2])\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program and the fitness decline from 1.4994 to 1.0388, I can see several areas for improvement. The current algorithm has good components but needs refinement in its exploration strategy and parameter tuning.\n\nHere are my suggested improvements:\n\n## Change 1: Improve Multi-Start Strategy with Better Coordination\n\nThe current multi-start approach runs independent searches. Let's make them cooperate by sharing information about promising regions.\n\n```python\n<<<<<<< SEARCH\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid optimization algorithm combining simulated annealing with local search.\n    Escapes local minima through temperature-based acceptance and adaptive step sizes.\n    \"\"\"\n    # Initialize with multiple starting points for better coverage\n    num_starts = 5\n    best_results = []\n    \n    for start in range(num_starts):\n=======\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid optimization algorithm combining simulated annealing with local search.\n    Escapes local minima through temperature-based acceptance and adaptive step sizes.\n    \"\"\"\n    # Initialize with multiple starting points for better coverage\n    num_starts = 5\n    best_results = []\n    global_best_value = float('inf')\n    promising_regions = []\n    \n    for start in range(num_starts):\n>>>>>>> REPLACE\n```\n\n## Change 2: Add Cooperative Search and Adaptive Restart Strategy\n\nReplace the random restart mechanism with an intelligent restart that uses information from other searches.\n\n```python\n<<<<<<< SEARCH\n            # Occasional random restart to escape deep local minima\n            if i > 0 and i % (iterations // (num_starts * 5)) == 0 and np.random.random() < 0.3:\n                x = np.random.uniform(bounds[0], bounds[1])\n                y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(x, y)\n                if current_value < best_value:\n                    best_x, best_y, best_value = x, y, current_value\n=======\n            # Intelligent restart based on global information\n            if i > 0 and i % (iterations // (num_starts * 4)) == 0:\n                # 40% chance to restart near promising regions or globally\n                if np.random.random() < 0.4:\n                    if len(promising_regions) > 0 and np.random.random() < 0.7:\n                        # Restart near a promising region\n                        region = promising_regions[np.random.randint(len(promising_regions))]\n                        x = region[0] + np.random.normal(0, 0.5)\n                        y = region[1] + np.random.normal(0, 0.5)\n                    else:\n                        # Global restart\n                        x = np.random.uniform(bounds[0], bounds[1])\n                        y = np.random.uniform(bounds[0], bounds[1])\n                    \n                    x = np.clip(x, bounds[0], bounds[1])\n                    y = np.clip(y, bounds[0], bounds[1])\n                    current_value = evaluate_function(x, y)\n                    if current_value < best_value:\n                        best_x, best_y, best_value = x, y, current_value\n                    # Reset momentum for fresh start\n                    momentum_x, momentum_y = 0, 0\n>>>>>>> REPLACE\n```\n\n## Change 3: Improve Temperature Schedule and Acceptance Criteria\n\nEnhance the temperature management and acceptance probability calculation.\n\n```python\n<<<<<<< SEARCH\n            # Adaptive cooling with occasional reheating\n            progress = i / (iterations // num_starts)\n            temp = initial_temp * (1 - progress) + final_temp * progress\n            \n            # Reheat if stuck in local minimum\n            if reheat_counter > 50 and temp < initial_temp * 0.3:\n                temp = min(temp * 2.0, initial_temp * 0.5)\n                reheat_counter = 0\n=======\n            # Enhanced temperature schedule with adaptive cooling\n            progress = i / (iterations // num_starts)\n            base_temp = initial_temp * (1 - progress) + final_temp * progress\n            \n            # Adaptive temperature based on improvement rate\n            if reheat_counter > 30:\n                # Stuck in local minimum - reheat more aggressively\n                temp = min(base_temp * 3.0, initial_temp * 0.6)\n                reheat_counter = 0\n            elif best_value < global_best_value:\n                # Found global improvement - cool faster to refine\n                temp = base_temp * 0.8\n                global_best_value = best_value\n            else:\n                temp = base_temp\n            \n            # Store promising regions for cooperative search\n            if i % 20 == 0 and best_value < -1.0:\n                promising_regions.append((best_x, best_y))\n                # Keep only top promising regions\n                if len(promising_regions) > 3:\n                    promising_regions.pop(0)\n>>>>>>> REPLACE\n```\n\n## Change 4: Enhance Final Refinement Phase\n\nImprove the local refinement with a more sophisticated multi-scale approach.\n\n```python\n<<<<<<< SEARCH\n    # Local refinement after each restart\n    if len(best_results) > 0:\n        best_current = min(best_results, key=lambda x: x[2])\n        local_step = 0.03 * (1 - start / num_starts)  # Decreasing step size\n        for _ in range(15):\n            local_candidate_x = best_current[0] + np.random.normal(0, local_step)\n            local_candidate_y = best_current[1] + np.random.normal(0, local_step)\n            local_candidate_x = np.clip(local_candidate_x, bounds[0], bounds[1])\n            local_candidate_y = np.clip(local_candidate_y, bounds[0], bounds[1])\n            local_value = evaluate_function(local_candidate_x, local_candidate_y)\n            if local_value < best_current[2]:\n                best_results[-1] = (local_candidate_x, local_candidate_y, local_value)\n=======\n    # Enhanced final refinement with multi-scale approach\n    if len(best_results) > 0:\n        best_current = min(best_results, key=lambda x: x[2])\n        \n        # Multi-scale refinement: from coarse to fine\n        scales = [0.05, 0.02, 0.008, 0.003]\n        for scale in scales:\n            for _ in range(12):\n                # Try multiple perturbation types\n                if np.random.random() < 0.6:\n                    # Gaussian perturbation\n                    dx = np.random.normal(0, scale)\n                    dy = np.random.normal(0, scale)\n                else:\n                    # Uniform perturbation for better coverage\n                    dx = np.random.uniform(-scale, scale)\n                    dy = np.random.uniform(-scale, scale)\n                \n                local_candidate_x = best_current[0] + dx\n                local_candidate_y = best_current[1] + dy\n                local_candidate_x = np.clip(local_candidate_x, bounds[0], bounds[1])\n                local_candidate_y = np.clip(local_candidate_y, bounds[0], bounds[1])\n                local_value = evaluate_function(local_candidate_x, local_candidate_y)\n                if local_value < best_current[2]:\n                    best_results[-1] = (local_candidate_x, local_candidate_y, local_value)\n                    best_current = (local_candidate_x, local_candidate_y, local_value)\n>>>>>>> REPLACE\n```\n\n## Reasoning for Changes:\n\n1. **Cooperative Search**: Instead of independent searches, the algorithm now shares information about promising regions, allowing searches to restart intelligently near good solutions.\n\n2. **Improved Restart Strategy**: The random restart is replaced with an intelligent restart that considers both global exploration and local exploitation of promising regions.\n\n3. **Enhanced Temperature Management**: The temperature schedule now adapts based on whether the search is making progress (cool faster) or stuck (reheat more aggressively).\n\n4. **Better Refinement**: The final refinement uses a multi-scale approach with both Gaussian and uniform perturbations for more thorough local search.\n\n5. **Global Best Tracking**: By tracking the global best value across all searches, the algorithm can make better decisions about when to explore vs exploit.\n\nThese changes should help the algorithm escape local minima more effectively while maintaining good convergence properties, addressing the fitness decline seen in the current implementation."]}}, "artifacts_json": "{\"stage1_result\": \"Found solution at x=-1.7043, y=0.6782 with value=-1.5187\", \"distance_to_global\": \"0.0004\", \"solution_quality\": \"Distance < 0.5: Very close\", \"convergence_info\": \"Converged in 10 trials with 10 successes\", \"best_position\": \"Final position: x=-1.7044, y=0.6763\", \"average_distance_to_global\": \"0.0080\", \"search_efficiency\": \"Success rate: 100.00%\"}", "artifact_dir": null, "embedding": null}