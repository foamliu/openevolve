{"id": "828dc142-12a7-4e26-857b-377bbb2b7b66", "code": "# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid optimization algorithm combining simulated annealing, local search, and adaptive sampling.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n    \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start initialization with 5 random points\n    starts = 5\n    best_x, best_y = None, None\n    best_value = float('inf')\n    \n    for _ in range(starts):\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        value = evaluate_function(x, y)\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n    \n    # Simulated annealing parameters\n    temp = 1.0\n    temp_min = 0.001\n    alpha = 0.995\n    \n    # Local search momentum\n    vx, vy = 0, 0\n    momentum = 0.7\n    learning_rate = 0.1\n    \n    x, y = best_x, best_y\n    current_value = best_value\n    \n    for i in range(iterations):\n        # Adaptive step size based on progress\n        progress = i / iterations\n        step_size = (1 - progress) * 2.0 + 0.1\n        \n        # Simulated annealing exploration\n        if np.random.random() < 0.3 or temp > 0.5:\n            # Global exploration with temperature-based acceptance\n            new_x = x + np.random.uniform(-step_size, step_size)\n            new_y = y + np.random.uniform(-step_size, step_size)\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n            \n            # Accept if better, or with probability based on temperature\n            if new_value < current_value or np.random.random() < np.exp(-(new_value - current_value) / temp):\n                x, y = new_x, new_y\n                current_value = new_value\n                vx, vy = 0, 0  # Reset momentum\n        else:\n            # Local gradient-based search with momentum\n            eps = 0.001\n            dx = (evaluate_function(x + eps, y) - evaluate_function(x - eps, y)) / (2 * eps)\n            dy = (evaluate_function(x, y + eps) - evaluate_function(x, y - eps)) / (2 * eps)\n            \n            # Update momentum\n            vx = momentum * vx - learning_rate * dx\n            vy = momentum * vy - learning_rate * dy\n            \n            # Apply momentum with decay\n            new_x = x + vx\n            new_y = y + vy\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n            \n            if new_value < current_value:\n                x, y = new_x, new_y\n                current_value = new_value\n        \n        # Update best\n        if current_value < best_value:\n            best_value = current_value\n            best_x, best_y = x, y\n        \n        # Cool down temperature\n        temp = max(temp_min, temp * alpha)\n    \n    # Final local refinement\n    refinement_steps = 50\n    x, y = best_x, best_y\n    for _ in range(refinement_steps):\n        eps = 0.0001\n        dx = (evaluate_function(x + eps, y) - evaluate_function(x - eps, y)) / (2 * eps)\n        dy = (evaluate_function(x, y + eps) - evaluate_function(x, y - eps)) / (2 * eps)\n        \n        new_x = x - 0.01 * dx\n        new_y = y - 0.01 * dy\n        new_x = np.clip(new_x, bounds[0], bounds[1])\n        new_y = np.clip(new_y, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n        \n        if new_value < best_value:\n            best_value = new_value\n            best_x, best_y = new_x, new_y\n            x, y = new_x, new_y\n        else:\n            break\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n", "language": "python", "parent_id": "8511c1a0-9902-4124-b11c-a07a13f246ea", "generation": 1, "timestamp": 1764998779.1360385, "iteration_found": 5, "metrics": {"runs_successfully": 1.0, "value_score": 0.9377715175987749, "distance_score": 0.3853951742827691, "combined_score": 0.7845043110842183, "reliability_score": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 27 lines with 107 lines", "parent_metrics": {"runs_successfully": 1.0, "value_score": 0.9417587299889709, "distance_score": 0.7565915427363771, "combined_score": 1.2147685971231066}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve a function minimization algorithm to find the global minimum of a complex function with many local minima. The function is f(x, y) = sin(x) * cos(y) + sin(x*y) + (x^2 + y^2)/20. Focus on improving the search_algorithm function to reliably find the global minimum, escaping local minima that might trap simple algorithms.", "user": "# Current Program Information\n- Fitness: 1.2148\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness unchanged at 1.2148\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: runs_successfully: 1.0000, value_score: 0.9418, distance_score: 0.7566, combined_score: 1.2148\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.2148)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A simple random search algorithm that often gets stuck in local minima.\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    best_x = np.random.uniform(bounds[0], bounds[1])\n    best_y = np.random.uniform(bounds[0], bounds[1])\n    best_value = evaluate_function(best_x, best_y)\n\n    for _ in range(iterations):\n        # Simple random search\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9418), Performs well on distance_score (0.7566), Performs well on combined_score (1.2148)\n\n\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A simple random search algorithm that often gets stuck in local minima.\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    best_x = np.random.uniform(bounds[0], bounds[1])\n    best_y = np.random.uniform(bounds[0], bounds[1])\n    best_value = evaluate_function(best_x, best_y)\n\n    for _ in range(iterations):\n        # Simple random search\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program, I can see it's using a simple random search that gets stuck in local minima. To improve the fitness score, I'll implement a hybrid approach combining multiple strategies: simulated annealing for escaping local minima, momentum-based local search for refinement, and adaptive step sizes. This will help find the global minimum more reliably.\n\nHere are my improvements:\n\n```python\n<<<<<<< SEARCH\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A simple random search algorithm that often gets stuck in local minima.\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    best_x = np.random.uniform(bounds[0], bounds[1])\n    best_y = np.random.uniform(bounds[0], bounds[1])\n    best_value = evaluate_function(best_x, best_y)\n\n    for _ in range(iterations):\n        # Simple random search\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n=======\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid optimization algorithm combining simulated annealing, local search, and adaptive sampling.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n    \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start initialization with 5 random points\n    starts = 5\n    best_x, best_y = None, None\n    best_value = float('inf')\n    \n    for _ in range(starts):\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        value = evaluate_function(x, y)\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n    \n    # Simulated annealing parameters\n    temp = 1.0\n    temp_min = 0.001\n    alpha = 0.995\n    \n    # Local search momentum\n    vx, vy = 0, 0\n    momentum = 0.7\n    learning_rate = 0.1\n    \n    x, y = best_x, best_y\n    current_value = best_value\n    \n    for i in range(iterations):\n        # Adaptive step size based on progress\n        progress = i / iterations\n        step_size = (1 - progress) * 2.0 + 0.1\n        \n        # Simulated annealing exploration\n        if np.random.random() < 0.3 or temp > 0.5:\n            # Global exploration with temperature-based acceptance\n            new_x = x + np.random.uniform(-step_size, step_size)\n            new_y = y + np.random.uniform(-step_size, step_size)\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n            \n            # Accept if better, or with probability based on temperature\n            if new_value < current_value or np.random.random() < np.exp(-(new_value - current_value) / temp):\n                x, y = new_x, new_y\n                current_value = new_value\n                vx, vy = 0, 0  # Reset momentum\n        else:\n            # Local gradient-based search with momentum\n            eps = 0.001\n            dx = (evaluate_function(x + eps, y) - evaluate_function(x - eps, y)) / (2 * eps)\n            dy = (evaluate_function(x, y + eps) - evaluate_function(x, y - eps)) / (2 * eps)\n            \n            # Update momentum\n            vx = momentum * vx - learning_rate * dx\n            vy = momentum * vy - learning_rate * dy\n            \n            # Apply momentum with decay\n            new_x = x + vx\n            new_y = y + vy\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n            \n            if new_value < current_value:\n                x, y = new_x, new_y\n                current_value = new_value\n        \n        # Update best\n        if current_value < best_value:\n            best_value = current_value\n            best_x, best_y = x, y\n        \n        # Cool down temperature\n        temp = max(temp_min, temp * alpha)\n    \n    # Final local refinement\n    refinement_steps = 50\n    x, y = best_x, best_y\n    for _ in range(refinement_steps):\n        eps = 0.0001\n        dx = (evaluate_function(x + eps, y) - evaluate_function(x - eps, y)) / (2 * eps)\n        dy = (evaluate_function(x, y + eps) - evaluate_function(x, y - eps)) / (2 * eps)\n        \n        new_x = x - 0.01 * dx\n        new_y = y - 0.01 * dy\n        new_x = np.clip(new_x, bounds[0], bounds[1])\n        new_y = np.clip(new_y, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n        \n        if new_value < best_value:\n            best_value = new_value\n            best_x, best_y = new_x, new_y\n            x, y = new_x, new_y\n        else:\n            break\n    \n    return best_x, best_y, best_value\n>>>>>>> REPLACE\n```\n\n**Key improvements made:**\n\n1. **Multi-start initialization**: Instead of starting from one random point, we start from 5 different random points and pick the best one.\n\n2. **Simulated annealing**: This helps escape local minima by occasionally accepting worse solutions with a probability that decreases over time (temperature cooling).\n\n3. **Adaptive step size**: The step size decreases as the algorithm progresses, allowing for coarse exploration early and fine refinement later.\n\n4. **Momentum-based local search**: Uses gradient information with momentum to efficiently navigate towards local minima once the global region is identified.\n\n5. **Hybrid strategy**: The algorithm switches between global exploration (30% of time or when temperature is high) and local exploitation based on gradients.\n\n6. **Final refinement**: A dedicated local refinement phase at the end to squeeze out the last bit of optimization.\n\nThis approach should significantly improve the ability to find the global minimum by combining the global search capabilities of simulated annealing with the local convergence speed of gradient-based methods, while the multi-start initialization helps ensure we don't miss promising regions of the search space."]}}, "artifacts_json": "{\"stage1_result\": \"Found solution at x=-1.7041, y=0.6775 with value=-1.5187\", \"distance_to_global\": \"0.0005\", \"solution_quality\": \"Distance < 0.5: Very close\", \"convergence_info\": \"Converged in 10 trials with 10 successes\", \"best_position\": \"Final position: x=-1.7041, y=0.6775\", \"average_distance_to_global\": \"1.5947\", \"search_efficiency\": \"Success rate: 100.00%\"}", "artifact_dir": null, "embedding": null}