{"id": "415ada27-2bb8-42f6-bce7-aacc2bd018e1", "code": "# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Efficient hybrid optimization with adaptive cooling and strategic exploration.\n    \"\"\"\n    # Initialize 5 candidates and find initial best\n    candidates = [(np.random.uniform(*bounds), np.random.uniform(*bounds)) for _ in range(5)]\n    values = [evaluate_function(x, y) for x, y in candidates]\n    \n    best_idx = np.argmin(values)\n    best_x, best_y = candidates[best_idx]\n    best_value = values[best_idx]\n    \n    # Adaptive temperature schedule\n    temp = 10.0\n    cooling_rate = 0.003  # More aggressive cooling\n    \n    for i in range(iterations):\n        # Progress-based step scaling\n        progress = i / iterations\n        step_scale = max(0.05, 1.5 * (1 - progress) * (temp / 10.0))\n        \n        for j in range(5):\n            x, y = candidates[j]\n            current_value = values[j]\n            \n            # Generate candidate with adaptive noise\n            new_x = np.clip(x + np.random.normal(0, step_scale), *bounds)\n            new_y = np.clip(y + np.random.normal(0, step_scale), *bounds)\n            new_value = evaluate_function(new_x, new_y)\n            \n            # Enhanced acceptance criteria\n            delta = new_value - current_value\n            if delta < 0 or (temp > 0.5 and np.random.random() < np.exp(-delta / temp)):\n                candidates[j] = (new_x, new_y)\n                values[j] = new_value\n                \n                if new_value < best_value:\n                    best_value = new_value\n                    best_x, best_y = new_x, new_y\n        \n        # Strategic exploration: replace worst with probability\n        if i % max(1, iterations // 10) == 0 and i > 0:\n            if np.random.random() < 0.3:  # 30% chance to explore\n                worst_idx = np.argmax(values)\n                candidates[worst_idx] = (np.random.uniform(*bounds), np.random.uniform(*bounds))\n                values[worst_idx] = evaluate_function(*candidates[worst_idx])\n                \n                if values[worst_idx] < best_value:\n                    best_value = values[worst_idx]\n                    best_x, best_y = candidates[worst_idx]\n        \n        # Adaptive cooling with restart protection\n        temp *= (1 - cooling_rate)\n        if temp < 0.1 and i < iterations * 0.8:  # Prevent premature convergence\n            temp = 0.5\n    \n    # Final focused refinement around best solution\n    refinement_steps = min(50, iterations // 20)\n    for i in range(refinement_steps):\n        step_size = 0.02 * (1 - i/refinement_steps)\n        for _ in range(3):  # Multiple tries per step\n            new_x = np.clip(best_x + np.random.normal(0, step_size), *bounds)\n            new_y = np.clip(best_y + np.random.normal(0, step_size), *bounds)\n            new_value = evaluate_function(new_x, new_y)\n            \n            if new_value < best_value:\n                best_value = new_value\n                best_x, best_y = new_x, new_y\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n", "language": "python", "parent_id": "38525711-82b4-4564-ab54-d26bcfe9f7cb", "generation": 3, "timestamp": 1765020662.1307833, "iteration_found": 22, "metrics": {"runs_successfully": 1.0, "value_score": 0.9996855682531439, "distance_score": 0.9992221515189812, "combined_score": 1.4994141443733997, "reliability_score": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 76 lines with 57 lines\nChange 2: Replace return best_x, best_y, best_value with 14 lines", "parent_metrics": {"runs_successfully": 1.0, "value_score": 0.9996315932149923, "distance_score": 0.9933748189414362, "combined_score": 1.4967423634348904, "reliability_score": 1.0}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve a function minimization algorithm to find the global minimum of a complex function with many local minima. The function is f(x, y) = sin(x) * cos(y) + sin(x*y) + (x^2 + y^2)/20. Focus on improving the search_algorithm function to reliably find the global minimum, escaping local minima that might trap simple algorithms.", "user": "# Current Program Information\n- Fitness: 1.4967\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness unchanged at 1.4967\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### stage1_result\n```\nFound solution at x=-1.7189, y=0.6674 with value=-1.5184\n```\n\n### distance_to_global\n```\n0.0183\n```\n\n### solution_quality\n```\nDistance < 0.5: Very close\n```\n\n### convergence_info\n```\nConverged in 10 trials with 10 successes\n```\n\n### best_position\n```\nFinal position: x=-1.7146, y=0.6759\n```\n\n### average_distance_to_global\n```\n0.0067\n```\n\n### search_efficiency\n```\nSuccess rate: 100.00%\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 56 lines with 76 lines\n- Metrics: runs_successfully: 1.0000, value_score: 0.9996, distance_score: 0.9934, combined_score: 1.4967, reliability_score: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Change 1: Replace 6 lines with 19 lines\nChange 2: Replace 11 lines with 24 lines\nChange 3: Replace 3 lines with 7 lines\nChange 4: Replace 2 lines with 9 lines\nChange 5: Replace 2 lines with 20 lines\n- Metrics: runs_successfully: 1.0000, value_score: 0.9997, distance_score: 0.9976, combined_score: 1.4987, reliability_score: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Change 1: Replace 27 lines with 78 lines\n- Metrics: runs_successfully: 1.0000, value_score: 0.9997, distance_score: 0.9995, combined_score: 1.4995, reliability_score: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.4995)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Adaptive differential evolution with local search hybrid.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Population size\n    pop_size = 20\n    \n    # Initialize population\n    population = np.random.uniform(bounds[0], bounds[1], (pop_size, 2))\n    values = np.array([evaluate_function(x, y) for x, y in population])\n    \n    # Track best solution\n    best_idx = np.argmin(values)\n    best_x, best_y = population[best_idx]\n    best_value = values[best_idx]\n    \n    # Adaptive parameters\n    mutation_factor = 0.8\n    crossover_prob = 0.7\n    \n    for i in range(iterations):\n        # Adaptive parameters based on progress\n        progress = i / iterations\n        mutation_factor = 0.5 + 0.3 * (1 - progress)\n        crossover_prob = 0.5 + 0.2 * (1 - progress)\n        \n        for j in range(pop_size):\n            # Select three random individuals (different from j)\n            candidates = list(range(pop_size))\n            candidates.remove(j)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Differential mutation\n            mutant = population[a] + mutation_factor * (population[b] - population[c])\n            \n            # Crossover\n            trial = population[j].copy()\n            crossover_mask = np.random.random(2) < crossover_prob\n            trial[crossover_mask] = mutant[crossover_mask]\n            \n            # Ensure bounds\n            trial = np.clip(trial, bounds[0], bounds[1])\n            \n            # Evaluate trial\n            trial_value = evaluate_function(trial[0], trial[1])\n            \n            # Selection\n            if trial_value < values[j]:\n                population[j] = trial\n                values[j] = trial_value\n                \n                # Update global best\n                if trial_value < best_value:\n                    best_x, best_y = trial[0], trial[1]\n                    best_value = trial_value\n        \n        # Periodic local search around best solution\n        if i % 50 == 0 and i > 0:\n            local_step = 0.1 * (1 - progress)\n            for _ in range(10):\n                local_x = best_x + np.random.normal(0, local_step)\n                local_y = best_y + np.random.normal(0, local_step)\n                local_x = np.clip(local_x, bounds[0], bounds[1])\n                local_y = np.clip(local_y, bounds[0], bounds[1])\n                local_value = evaluate_function(local_x, local_y)\n                \n                if local_value < best_value:\n                    best_x, best_y = local_x, local_y\n                    best_value = local_value\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9997), Performs well on distance_score (0.9995), Performs well on combined_score (1.4995), Performs well on reliability_score (1.0000)\n\n### Program 2 (Score: 1.4987)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid optimization algorithm combining simulated annealing with local search.\n    Escapes local minima through temperature-based acceptance and adaptive step sizes.\n    \"\"\"\n    # Initialize with multiple starting points for better coverage\n    num_starts = 5\n    best_results = []\n    \n    for start in range(num_starts):\n        # Enhanced simulated annealing parameters\n        temp = 2.0  # Higher initial temperature for better exploration\n        initial_temp = temp\n        # Adaptive cooling: faster cooling when temperature is high, slower when low\n        base_cooling = 0.995\n        # Also add occasional reheating to escape deep local minima\n        reheat_frequency = iterations // (num_starts * 4)\n        \n        # Initialize current point\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(x, y)\n        \n        best_x, best_y, best_value = x, y, current_value\n        \n        # Adaptive step size based on bounds\n        step_size = (bounds[1] - bounds[0]) * 0.1\n        \n        # Initialize momentum\n        momentum_x, momentum_y = 0, 0\n        \n        for i in range(iterations // num_starts):\n            # Adaptive step size based on iteration progress and temperature\n            progress = i / (iterations // num_starts)\n            temp_ratio = temp  # Temperature affects step size\n            current_step_size = step_size * (1 - progress) * temp_ratio\n            \n            # Generate candidate with momentum and Gaussian perturbation\n            random_dx = np.random.normal(0, current_step_size)\n            random_dy = np.random.normal(0, current_step_size)\n            \n            # Combine momentum with random walk (momentum helps escape local minima)\n            dx = 0.3 * momentum_x + 0.7 * random_dx\n            dy = 0.3 * momentum_y + 0.7 * random_dy\n            \n            candidate_x = x + dx\n            candidate_y = y + dy\n            \n            # Ensure bounds\n            candidate_x = np.clip(candidate_x, bounds[0], bounds[1])\n            candidate_y = np.clip(candidate_y, bounds[0], bounds[1])\n            \n            candidate_value = evaluate_function(candidate_x, candidate_y)\n            \n            # Accept if better, or with enhanced temperature-based probability\n            if candidate_value < current_value:\n                x, y, current_value = candidate_x, candidate_y, candidate_value\n                if candidate_value < best_value:\n                    best_x, best_y, best_value = candidate_x, candidate_y, candidate_value\n                # Update momentum in direction of improvement\n                momentum_x = dx * 0.5\n                momentum_y = dy * 0.5\n            else:\n                # Enhanced acceptance for escaping local minima\n                delta = candidate_value - current_value\n                # Adaptive acceptance based on search progress and temperature\n                progress_factor = 1.0 + (iterations // num_starts - i) / (iterations // num_starts)\n                acceptance_prob = np.exp(-delta / (temp * progress_factor))\n                \n                if np.random.random() < acceptance_prob:\n                    x, y, current_value = candidate_x, candidate_y, candidate_value\n                    # Reduce momentum on uphill moves but don't zero it\n                    momentum_x *= 0.3\n                    momentum_y *= 0.3\n                else:\n                    # Decay momentum when move is rejected\n                    momentum_x *= 0.8\n                    momentum_y *= 0.8\n            \n            # Adaptive cooling based on temperature level\n            if temp > initial_temp * 0.5:\n                temp *= base_cooling  # Normal cooling\n            else:\n                temp *= (base_cooling + 0.002)  # Slower cooling at low temperatures\n            \n            # Occasional reheating to escape deep local minima\n            if i % reheat_frequency == 0 and i > 0 and temp < initial_temp * 0.1:\n                temp = min(temp * 2.0, initial_temp * 0.3)\n        \n        best_results.append((best_x, best_y, best_value))\n    \n    # Get the best result from all starts\n    best_x, best_y, best_value = min(best_results, key=lambda x: x[2])\n    \n    # Final local refinement phase\n    refinement_steps = iterations // 20\n    refinement_step_size = (bounds[1] - bounds[0]) * 0.005\n    \n    for i in range(refinement_steps):\n        # Very small Gaussian perturbations for fine-tuning\n        dx = np.random.normal(0, refinement_step_size * (1 - i/refinement_steps))\n        dy = np.random.normal(0, refinement_step_size * (1 - i/refinement_steps))\n        \n        new_x = np.clip(best_x + dx, bounds[0], bounds[1])\n        new_y = np.clip(best_y + dy, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n        \n        if new_value < best_value:\n            best_x, best_y, best_value = new_x, new_y, new_value\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9997), Performs well on distance_score (0.9976), Performs well on combined_score (1.4987), Performs well on reliability_score (1.0000)\n\n### Program 3 (Score: 1.4967)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Advanced hybrid search combining simulated annealing, local search, and multi-start strategy.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n    \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start with 5 candidates for better coverage (increased from 3)\n    candidates = []\n    for _ in range(5):\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        value = evaluate_function(x, y)\n        candidates.append((x, y, value))\n    \n    # Simulated annealing parameters with better cooling schedule\n    initial_temp = 10.0\n    final_temp = 0.01\n    cooling_rate = (final_temp / initial_temp) ** (1.0 / iterations)\n    temperature = initial_temp\n    \n    # Track global best for better convergence\n    best_idx = min(range(5), key=lambda i: candidates[i][2])\n    best_x, best_y, best_value = candidates[best_idx]\n    \n    for i in range(iterations):\n        # Update temperature with exponential cooling\n        temperature *= cooling_rate\n        \n        for j, (x, y, current_value) in enumerate(candidates):\n            # Adaptive step size based on iteration progress\n            if i < iterations // 3:\n                # Early exploration: larger steps\n                step_scale = 2.0 * (1 - i/iterations)\n            else:\n                # Late refinement: smaller steps focused around best\n                step_scale = max(0.1, 0.5 * (1 - i/iterations))\n            \n            # Local perturbation with Gaussian noise\n            new_x = x + np.random.normal(0, step_scale)\n            new_y = y + np.random.normal(0, step_scale)\n            \n            # Keep within bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            \n            new_value = evaluate_function(new_x, new_y)\n            \n            # Accept if better, or with probability if worse (simulated annealing)\n            delta = new_value - current_value\n            if delta < 0 or (temperature > 0.1 and np.random.random() < np.exp(-delta / temperature)):\n                candidates[j] = (new_x, new_y, new_value)\n                \n                # Update global best when we find a better solution\n                if new_value < best_value:\n                    best_value = new_value\n                    best_x, best_y = new_x, new_y\n        \n        # Strategic long-range exploration: replace worst candidate\n        if i % (iterations // 8) == 0 and i > 0:\n            worst_idx = max(range(5), key=lambda i: candidates[i][2])\n            x = np.random.uniform(bounds[0], bounds[1])\n            y = np.random.uniform(bounds[0], bounds[1])\n            value = evaluate_function(x, y)\n            candidates[worst_idx] = (x, y, value)\n            \n            # Update global best if needed\n            if value < best_value:\n                best_value = value\n                best_x, best_y = x, y\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9996), Performs well on distance_score (0.9934), Performs well on combined_score (1.4967), Performs well on reliability_score (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 1.4910)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Advanced hybrid optimization algorithm combining multiple strategies\n    to escape local minima and find the global minimum.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n    \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start strategy: maintain multiple candidates\n    num_candidates = 5\n    candidates = []\n    for _ in range(num_candidates):\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        candidates.append((x, y, evaluate_function(x, y)))\n    \n    # Simulated annealing parameters\n    initial_temp = 10.0\n    final_temp = 0.01\n    cooling_rate = (final_temp / initial_temp) ** (1.0 / iterations)\n    temperature = initial_temp\n    \n    # Adaptive step size\n    step_size = (bounds[1] - bounds[0]) * 0.1\n    min_step_size = (bounds[1] - bounds[0]) * 0.001\n    \n    # Track best solution\n    best_idx = min(range(num_candidates), key=lambda i: candidates[i][2])\n    best_x, best_y, best_value = candidates[best_idx]\n    \n    for iter in range(iterations):\n        # Update temperature\n        temperature *= cooling_rate\n        \n        # Try to improve each candidate\n        for i in range(num_candidates):\n            x, y, value = candidates[i]\n            \n            # Local refinement with adaptive step\n            if iter > iterations // 4:  # Start local refinement after initial exploration\n                dx = np.random.normal(0, step_size)\n                dy = np.random.normal(0, step_size)\n            else:\n                # Global search with larger steps\n                dx = np.random.uniform(-step_size * 3, step_size * 3)\n                dy = np.random.uniform(-step_size * 3, step_size * 3)\n            \n            new_x = np.clip(x + dx, bounds[0], bounds[1])\n            new_y = np.clip(y + dy, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n            \n            # Accept or reject based on simulated annealing\n            delta = new_value - value\n            if delta < 0 or (temperature > 0.1 and np.random.random() < np.exp(-delta / temperature)):\n                candidates[i] = (new_x, new_y, new_value)\n                \n                # Update global best\n                if new_value < best_value:\n                    best_value = new_value\n                    best_x, best_y = new_x, new_y\n                    # Reduce step size when we find a better solution\n                    step_size = max(step_size * 0.9, min_step_size)\n        \n        # Occasional random restart to escape deep local minima\n        if iter % (iterations // 10) == 0 and iter > 0:\n            worst_idx = max(range(num_candidates), key=lambda i: candidates[i][2])\n            candidates[worst_idx] = (\n                np.random.uniform(bounds[0], bounds[1]),\n                np.random.uniform(bounds[0], bounds[1]),\n                evaluate_function(candidates[worst_idx][0], candidates[worst_idx][1])\n            )\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to value_score\n\n### Program D2 (Score: 1.4962)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid simulated annealing with local refinement to escape local minima.\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multiple restarts from different starting points\n    num_restarts = 5\n    restart_iterations = iterations // num_restarts\n    \n    best_global_x = np.random.uniform(bounds[0], bounds[1])\n    best_global_y = np.random.uniform(bounds[0], bounds[1])\n    best_global_value = evaluate_function(best_global_x, best_global_y)\n    \n    for restart in range(num_restarts):\n        # Initialize restart point\n        if restart == 0:\n            x, y = best_global_x, best_global_y\n        else:\n            x = np.random.uniform(bounds[0], bounds[1])\n            y = np.random.uniform(bounds[0], bounds[1])\n        \n        current_value = evaluate_function(x, y)\n        best_restart_value = current_value\n        best_restart_x, best_restart_y = x, y\n        \n        # Initial temperature for simulated annealing\n        temp = 2.0\n        temp_decay = 0.95\n        \n        for i in range(restart_iterations):\n            # Adaptive step size based on iteration progress\n            step_scale = max(0.1, 2.0 * (1 - i/restart_iterations))\n            \n            # Generate candidate with local search bias\n            if i < restart_iterations * 0.7:\n                # Global exploration with simulated annealing\n                dx = np.random.normal(0, step_scale)\n                dy = np.random.normal(0, step_scale)\n            else:\n                # Local refinement around best point\n                dx = np.random.normal(0, step_scale * 0.3)\n                dy = np.random.normal(0, step_scale * 0.3)\n            \n            new_x = np.clip(x + dx, bounds[0], bounds[1])\n            new_y = np.clip(y + dy, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n            \n            # Accept or reject based on simulated annealing\n            if new_value < current_value:\n                # Always accept better solutions\n                x, y = new_x, new_y\n                current_value = new_value\n            else:\n                # Sometimes accept worse solutions to escape local minima\n                delta = new_value - current_value\n                prob = np.exp(-delta / temp)\n                if np.random.random() < prob:\n                    x, y = new_x, new_y\n                    current_value = new_value\n            \n            # Update best for this restart\n            if current_value < best_restart_value:\n                best_restart_value = current_value\n                best_restart_x, best_restart_y = x, y\n            \n            # Cool down temperature\n            temp *= temp_decay\n        \n        # Update global best\n        if best_restart_value < best_global_value:\n            best_global_value = best_restart_value\n            best_global_x, best_global_y = best_restart_x, best_restart_y\n    \n    return best_global_x, best_global_y, best_global_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to value_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid simulated annealing with local refinement to escape local minima.\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multiple restarts from different starting points\n    num_restarts = 5\n    restart_iterations = iterations // num_restarts\n    \n    best_global_x = np.random.uniform(bounds[0], bounds[1])\n    best_global_y = np.random.uniform(bounds[0], bounds[1])\n    best_global_value = evaluate_function(best_global_x, best_global_y)\n    \n    for restart in range(num_restarts):\n        # Initialize restart point\n        if restart == 0:\n            x, y = best_global_x, best_global_y\n        else:\n            x = np.random.uniform(bounds[0], bounds[1])\n            y = np.random.uniform(bounds[0], bounds[1])\n        \n        current_value = evaluate_function(x, y)\n        best_restart_value = current_value\n        best_restart_x, best_restart_y = x, y\n        \n        # Initial temperature for simulated annealing with adaptive scheduling\n        temp = 5.0\n        initial_temp = temp\n        # Adaptive temperature decay based on search progress\n        temp_decay = 0.98 if restart == 0 else 0.95\n        \n        for i in range(restart_iterations):\n            # Adaptive step size based on both iteration progress and temperature\n            temp_ratio = temp / initial_temp\n            step_scale = max(0.05, 2.0 * (1 - i/restart_iterations) * temp_ratio)\n            \n            # Generate candidate with momentum and adaptive search strategy\n            if i == 0:\n                # Initialize momentum\n                momentum_x, momentum_y = 0, 0\n            \n            if i < restart_iterations * 0.6:\n                # Global exploration with momentum\n                random_dx = np.random.normal(0, step_scale)\n                random_dy = np.random.normal(0, step_scale)\n                dx = 0.3 * momentum_x + 0.7 * random_dx\n                dy = 0.3 * momentum_y + 0.7 * random_dy\n            elif i < restart_iterations * 0.9:\n                # Local refinement with reduced momentum\n                dx = np.random.normal(0, step_scale * 0.3)\n                dy = np.random.normal(0, step_scale * 0.3)\n            else:\n                # Very local fine-tuning\n                dx = np.random.normal(0, step_scale * 0.1)\n                dy = np.random.normal(0, step_scale * 0.1)\n            \n            new_x = np.clip(x + dx, bounds[0], bounds[1])\n            new_y = np.clip(y + dy, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n            \n            # Accept or reject based on enhanced simulated annealing\n            if new_value < current_value:\n                # Always accept better solutions and update momentum\n                x, y = new_x, new_y\n                current_value = new_value\n                momentum_x = dx * 0.5\n                momentum_y = dy * 0.5\n            else:\n                # Enhanced acceptance for escaping local minima\n                delta = new_value - current_value\n                # Adaptive acceptance probability based on search progress\n                acceptance_boost = 1.0 + (restart_iterations - i) / restart_iterations\n                prob = np.exp(-delta / (temp * acceptance_boost))\n                if np.random.random() < prob:\n                    x, y = new_x, new_y\n                    current_value = new_value\n                    # Reduce momentum on uphill moves\n                    momentum_x *= 0.3\n                    momentum_y *= 0.3\n            \n            # Update best for this restart\n            if current_value < best_restart_value:\n                best_restart_value = current_value\n                best_restart_x, best_restart_y = x, y\n                # Reset stagnation counter when improvement found\n                stagnation_counter = 0\n            else:\n                stagnation_counter += 1\n            \n            # Cool down temperature\n            temp *= temp_decay\n            \n            # Early restart if stuck in local minimum\n            if stagnation_counter > restart_iterations // 4 and i < restart_iterations * 0.8:\n                break\n        \n        # Update global best\n        if best_restart_value < best_global_value:\n            best_global_value = best_restart_value\n            best_global_x, best_global_y = best_restart_x, best_restart_y\n    \n    # Final local refinement around the best solution\n    refinement_iterations = iterations // 10\n    x, y = best_global_x, best_global_y\n    best_value = best_global_value\n    \n    for i in range(refinement_iterations):\n        # Very small steps for fine-tuning\n        step_size = 0.01 * (1 - i/refinement_iterations)\n        dx = np.random.normal(0, step_size)\n        dy = np.random.normal(0, step_size)\n        \n        new_x = np.clip(x + dx, bounds[0], bounds[1])\n        new_y = np.clip(y + dy, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n        \n        if new_value < best_value:\n            x, y, best_value = new_x, new_y, new_value\n    \n    return x, y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Alternative runs_successfully approach, Alternative combined_score approach, NumPy-based implementation\n\n### Inspiration 2 (Score: 1.4995, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Adaptive differential evolution with local search hybrid.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Population size\n    pop_size = 20\n    \n    # Initialize population\n    population = np.random.uniform(bounds[0], bounds[1], (pop_size, 2))\n    values = np.array([evaluate_function(x, y) for x, y in population])\n    \n    # Track best solution\n    best_idx = np.argmin(values)\n    best_x, best_y = population[best_idx]\n    best_value = values[best_idx]\n    \n    # Adaptive parameters\n    mutation_factor = 0.8\n    crossover_prob = 0.7\n    \n    for i in range(iterations):\n        # Adaptive parameters based on progress\n        progress = i / iterations\n        mutation_factor = 0.5 + 0.3 * (1 - progress)\n        crossover_prob = 0.5 + 0.2 * (1 - progress)\n        \n        for j in range(pop_size):\n            # Select three random individuals (different from j)\n            candidates = list(range(pop_size))\n            candidates.remove(j)\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            \n            # Differential mutation\n            mutant = population[a] + mutation_factor * (population[b] - population[c])\n            \n            # Crossover\n            trial = population[j].copy()\n            crossover_mask = np.random.random(2) < crossover_prob\n            trial[crossover_mask] = mutant[crossover_mask]\n            \n            # Ensure bounds\n            trial = np.clip(trial, bounds[0], bounds[1])\n            \n            # Evaluate trial\n            trial_value = evaluate_function(trial[0], trial[1])\n            \n            # Selection\n            if trial_value < values[j]:\n                population[j] = trial\n                values[j] = trial_value\n                \n                # Update global best\n                if trial_value < best_value:\n                    best_x, best_y = trial[0], trial[1]\n                    best_value = trial_value\n        \n        # Periodic local search around best solution\n        if i % 50 == 0 and i > 0:\n            local_step = 0.1 * (1 - progress)\n            for _ in range(10):\n                local_x = best_x + np.random.normal(0, local_step)\n                local_y = best_y + np.random.normal(0, local_step)\n                local_x = np.clip(local_x, bounds[0], bounds[1])\n                local_y = np.clip(local_y, bounds[0], bounds[1])\n                local_value = evaluate_function(local_x, local_y)\n                \n                if local_value < best_value:\n                    best_x, best_y = local_x, local_y\n                    best_value = local_value\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Modification: Change 1: Replace 27 lines with 78 lines, Excellent runs_successfully (1.000), Excellent value_score (1.000)\n\n### Inspiration 3 (Score: 0.9702, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid optimization algorithm combining simulated annealing with local search.\n    Escapes local minima through temperature-based acceptance and adaptive step sizes.\n    \"\"\"\n    # Initialize with multiple starting points for better coverage\n    num_starts = 5\n    best_results = []\n    \n    for start in range(num_starts):\n        # Simulated annealing parameters with adaptive cooling\n        initial_temp = 2.0\n        final_temp = 0.01\n        temp = initial_temp\n        \n        # Initialize current point\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(x, y)\n        \n        best_x, best_y, best_value = x, y, current_value\n        \n        # Adaptive step size based on bounds\n        step_size = (bounds[1] - bounds[0]) * 0.1\n        \n        for i in range(iterations // num_starts):\n            # Occasional random restart to escape deep local minima\n            if i > 0 and i % (iterations // (num_starts * 5)) == 0 and np.random.random() < 0.3:\n                x = np.random.uniform(bounds[0], bounds[1])\n                y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(x, y)\n                if current_value < best_value:\n                    best_x, best_y, best_value = x, y, current_value\n            # Generate candidate with adaptive Gaussian perturbations\n            step_scale = step_size * (1 - i / (iterations // num_starts))\n            candidate_x = x + np.random.normal(0, step_scale)\n            candidate_y = y + np.random.normal(0, step_scale)\n            \n            # Ensure bounds\n            candidate_x = np.clip(candidate_x, bounds[0], bounds[1])\n            candidate_y = np.clip(candidate_y, bounds[0], bounds[1])\n            \n            candidate_value = evaluate_function(candidate_x, candidate_y)\n            \n            # Accept if better, or with temperature-based probability\n            if candidate_value < current_value:\n                x, y, current_value = candidate_x, candidate_y, candidate_value\n                if candidate_value < best_value:\n                    best_x, best_y, best_value = candidate_x, candidate_y, candidate_value\n            else:\n                # Accept worse solutions with decreasing probability\n                delta = candidate_value - current_value\n                prob = np.exp(-delta / temp)\n                if np.random.random() < prob:\n                    x, y, current_value = candidate_x, candidate_y, candidate_value\n            \n            # Adaptive cooling based on progress\n            progress = i / (iterations // num_starts)\n            temp = initial_temp * (1 - progress) + final_temp * progress\n        \n        best_results.append((best_x, best_y, best_value))\n    \n    # Add local refinement around the best solution found so far\n    if start % 2 == 0 and start > 0:  # Every other restart, do local refinement\n        best_current = min(best_results, key=lambda x: x[2])\n        local_step = 0.05\n        for _ in range(20):\n            local_candidate_x = best_current[0] + np.random.normal(0, local_step)\n            local_candidate_y = best_current[1] + np.random.normal(0, local_step)\n            local_candidate_x = np.clip(local_candidate_x, bounds[0], bounds[1])\n            local_candidate_y = np.clip(local_candidate_y, bounds[0], bounds[1])\n            local_value = evaluate_function(local_candidate_x, local_candidate_y)\n            if local_value < best_current[2]:\n                best_results[-1] = (local_candidate_x, local_candidate_y, local_value)\n    \n    # Return the best result from all starts\n    return min(best_results, key=lambda x: x[2])\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Excellent runs_successfully (1.000), Excellent value_score (0.955), Excellent combined_score (0.970)\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Advanced hybrid search combining simulated annealing, local search, and multi-start strategy.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n    \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start with 5 candidates for better coverage (increased from 3)\n    candidates = []\n    for _ in range(5):\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        value = evaluate_function(x, y)\n        candidates.append((x, y, value))\n    \n    # Simulated annealing parameters with better cooling schedule\n    initial_temp = 10.0\n    final_temp = 0.01\n    cooling_rate = (final_temp / initial_temp) ** (1.0 / iterations)\n    temperature = initial_temp\n    \n    # Track global best for better convergence\n    best_idx = min(range(5), key=lambda i: candidates[i][2])\n    best_x, best_y, best_value = candidates[best_idx]\n    \n    for i in range(iterations):\n        # Update temperature with exponential cooling\n        temperature *= cooling_rate\n        \n        for j, (x, y, current_value) in enumerate(candidates):\n            # Adaptive step size based on iteration progress\n            if i < iterations // 3:\n                # Early exploration: larger steps\n                step_scale = 2.0 * (1 - i/iterations)\n            else:\n                # Late refinement: smaller steps focused around best\n                step_scale = max(0.1, 0.5 * (1 - i/iterations))\n            \n            # Local perturbation with Gaussian noise\n            new_x = x + np.random.normal(0, step_scale)\n            new_y = y + np.random.normal(0, step_scale)\n            \n            # Keep within bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            \n            new_value = evaluate_function(new_x, new_y)\n            \n            # Accept if better, or with probability if worse (simulated annealing)\n            delta = new_value - current_value\n            if delta < 0 or (temperature > 0.1 and np.random.random() < np.exp(-delta / temperature)):\n                candidates[j] = (new_x, new_y, new_value)\n                \n                # Update global best when we find a better solution\n                if new_value < best_value:\n                    best_value = new_value\n                    best_x, best_y = new_x, new_y\n        \n        # Strategic long-range exploration: replace worst candidate\n        if i % (iterations // 8) == 0 and i > 0:\n            worst_idx = max(range(5), key=lambda i: candidates[i][2])\n            x = np.random.uniform(bounds[0], bounds[1])\n            y = np.random.uniform(bounds[0], bounds[1])\n            value = evaluate_function(x, y)\n            candidates[worst_idx] = (x, y, value)\n            \n            # Update global best if needed\n            if value < best_value:\n                best_value = value\n                best_x, best_y = x, y\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program and the performance metrics, I can see it's achieving good results (fitness 1.4967, 100% success rate, very close to global minimum). However, there are several areas where we can improve:\n\n1. **Code length optimization** - The current implementation is quite verbose\n2. **Search efficiency** - We can enhance the exploration/exploitation balance\n3. **Convergence speed** - Better adaptive mechanisms can reduce iterations needed\n\nHere are my targeted improvements:\n\n## Change 1: Simplify and optimize the main search loop\n\n```python\n<<<<<<< SEARCH\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Advanced hybrid search combining simulated annealing, local search, and multi-start strategy.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n    \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start with 5 candidates for better coverage (increased from 3)\n    candidates = []\n    for _ in range(5):\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        value = evaluate_function(x, y)\n        candidates.append((x, y, value))\n    \n    # Simulated annealing parameters with better cooling schedule\n    initial_temp = 10.0\n    final_temp = 0.01\n    cooling_rate = (final_temp / initial_temp) ** (1.0 / iterations)\n    temperature = initial_temp\n    \n    # Track global best for better convergence\n    best_idx = min(range(5), key=lambda i: candidates[i][2])\n    best_x, best_y, best_value = candidates[best_idx]\n    \n    for i in range(iterations):\n        # Update temperature with exponential cooling\n        temperature *= cooling_rate\n        \n        for j, (x, y, current_value) in enumerate(candidates):\n            # Adaptive step size based on iteration progress\n            if i < iterations // 3:\n                # Early exploration: larger steps\n                step_scale = 2.0 * (1 - i/iterations)\n            else:\n                # Late refinement: smaller steps focused around best\n                step_scale = max(0.1, 0.5 * (1 - i/iterations))\n            \n            # Local perturbation with Gaussian noise\n            new_x = x + np.random.normal(0, step_scale)\n            new_y = y + np.random.normal(0, step_scale)\n            \n            # Keep within bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            \n            new_value = evaluate_function(new_x, new_y)\n            \n            # Accept if better, or with probability if worse (simulated annealing)\n            delta = new_value - current_value\n            if delta < 0 or (temperature > 0.1 and np.random.random() < np.exp(-delta / temperature)):\n                candidates[j] = (new_x, new_y, new_value)\n                \n                # Update global best when we find a better solution\n                if new_value < best_value:\n                    best_value = new_value\n                    best_x, best_y = new_x, new_y\n        \n        # Strategic long-range exploration: replace worst candidate\n        if i % (iterations // 8) == 0 and i > 0:\n            worst_idx = max(range(5), key=lambda i: candidates[i][2])\n            x = np.random.uniform(bounds[0], bounds[1])\n            y = np.random.uniform(bounds[0], bounds[1])\n            value = evaluate_function(x, y)\n            candidates[worst_idx] = (x, y, value)\n            \n            # Update global best if needed\n            if value < best_value:\n                best_value = value\n                best_x, best_y = x, y\n    \n    return best_x, best_y, best_value\n=======\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Efficient hybrid optimization with adaptive cooling and strategic exploration.\n    \"\"\"\n    # Initialize 5 candidates and find initial best\n    candidates = [(np.random.uniform(*bounds), np.random.uniform(*bounds)) for _ in range(5)]\n    values = [evaluate_function(x, y) for x, y in candidates]\n    \n    best_idx = np.argmin(values)\n    best_x, best_y = candidates[best_idx]\n    best_value = values[best_idx]\n    \n    # Adaptive temperature schedule\n    temp = 10.0\n    cooling_rate = 0.003  # More aggressive cooling\n    \n    for i in range(iterations):\n        # Progress-based step scaling\n        progress = i / iterations\n        step_scale = max(0.05, 1.5 * (1 - progress) * (temp / 10.0))\n        \n        for j in range(5):\n            x, y = candidates[j]\n            current_value = values[j]\n            \n            # Generate candidate with adaptive noise\n            new_x = np.clip(x + np.random.normal(0, step_scale), *bounds)\n            new_y = np.clip(y + np.random.normal(0, step_scale), *bounds)\n            new_value = evaluate_function(new_x, new_y)\n            \n            # Enhanced acceptance criteria\n            delta = new_value - current_value\n            if delta < 0 or (temp > 0.5 and np.random.random() < np.exp(-delta / temp)):\n                candidates[j] = (new_x, new_y)\n                values[j] = new_value\n                \n                if new_value < best_value:\n                    best_value = new_value\n                    best_x, best_y = new_x, new_y\n        \n        # Strategic exploration: replace worst with probability\n        if i % max(1, iterations // 10) == 0 and i > 0:\n            if np.random.random() < 0.3:  # 30% chance to explore\n                worst_idx = np.argmax(values)\n                candidates[worst_idx] = (np.random.uniform(*bounds), np.random.uniform(*bounds))\n                values[worst_idx] = evaluate_function(*candidates[worst_idx])\n                \n                if values[worst_idx] < best_value:\n                    best_value = values[worst_idx]\n                    best_x, best_y = candidates[worst_idx]\n        \n        # Adaptive cooling with restart protection\n        temp *= (1 - cooling_rate)\n        if temp < 0.1 and i < iterations * 0.8:  # Prevent premature convergence\n            temp = 0.5\n    \n    return best_x, best_y, best_value\n>>>>>>> REPLACE\n```\n\n## Change 2: Add final local refinement phase\n\n```python\n<<<<<<< SEARCH\n    return best_x, best_y, best_value\n=======\n    # Final focused refinement around best solution\n    refinement_steps = min(50, iterations // 20)\n    for i in range(refinement_steps):\n        step_size = 0.02 * (1 - i/refinement_steps)\n        for _ in range(3):  # Multiple tries per step\n            new_x = np.clip(best_x + np.random.normal(0, step_size), *bounds)\n            new_y = np.clip(best_y + np.random.normal(0, step_size), *bounds)\n            new_value = evaluate_function(new_x, new_y)\n            \n            if new_value < best_value:\n                best_value = new_value\n                best_x, best_y = new_x, new_y\n    \n    return best_x, best_y, best_value\n>>>>>>> REPLACE\n```\n\n## Key Improvements Explained:\n\n1. **Code Simplification**: Reduced from ~80 lines to ~50 lines while maintaining functionality\n2. **Efficiency**: \n   - Vectorized candidate management using lists instead of tuples for easier updates\n   - More aggressive cooling schedule (0.003 vs previous exponential decay)\n   - Progress-based step scaling that's more responsive to search progress\n\n3. **Better Exploration/Exploitation Balance**:\n   - Strategic exploration with 30% probability to replace worst candidate\n   - Temperature restart protection to prevent premature convergence\n   - Enhanced final refinement phase with multiple tries per step\n\n4. **Improved Convergence**:\n   - More responsive step scaling based on both progress and temperature\n   - Better bounds handling using tuple unpacking\n   - Focused local refinement at the end\n\nThese changes should improve the fitness score by:\n- Reducing code complexity while maintaining robustness\n- Improving search efficiency through better adaptive mechanisms\n- Enhancing the ability to escape local minima through strategic exploration\n- Providing more reliable convergence to the global minimum"]}}, "artifacts_json": "{\"stage1_result\": \"Found solution at x=-1.7039, y=0.6774 with value=-1.5187\", \"distance_to_global\": \"0.0006\", \"solution_quality\": \"Distance < 0.5: Very close\", \"convergence_info\": \"Converged in 10 trials with 10 successes\", \"best_position\": \"Final position: x=-1.7059, y=0.6772\", \"average_distance_to_global\": \"0.0008\", \"search_efficiency\": \"Success rate: 100.00%\"}", "artifact_dir": null, "embedding": null}