{"id": "2bfabd58-23f8-4633-9ea8-9dae54693a79", "code": "# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Efficient hybrid search with multiple candidates and adaptive cooling.\n    \"\"\"\n    # Initialize 8 diverse candidates with Latin Hypercube sampling\n    candidates = []\n    for i in range(8):\n        # Latin Hypercube sampling for better coverage\n        x = bounds[0] + (i + 0.5) * (bounds[1] - bounds[0]) / 8 + np.random.uniform(-0.3, 0.3)\n        y = bounds[0] + np.random.uniform(0, 8) * (bounds[1] - bounds[0]) / 8 + np.random.uniform(-0.3, 0.3)\n        x = np.clip(x, bounds[0], bounds[1])\n        y = np.clip(y, bounds[0], bounds[1])\n        candidates.append([x, y, evaluate_function(x, y)])\n    \n    # Sort by value and preserve elite\n    candidates.sort(key=lambda x: x[2])\n    best_x, best_y, best_value = candidates[0]\n    elite = candidates[0]  # Preserve best solution\n    \n    # Simulated annealing parameters\n    temp = 2.0\n    temp_decay = 0.995\n    min_temp = 0.01\n    \n    for i in range(iterations):\n        # Select random candidate for exploration\n        idx = np.random.randint(0, len(candidates))\n        x, y, val = candidates[idx]\n        \n        # Adaptive step size based on temperature and progress\n        step_scale = min(1.0, temp) * (1 - i/iterations * 0.8)\n        step_size = step_scale * (bounds[1] - bounds[0]) / 5\n        \n        # Mix exploration strategies based on temperature and progress\n        if temp > 0.5 or np.random.random() < 0.3:\n            # Heavy-tailed Cauchy distribution for better exploration\n            new_x = x + np.random.standard_cauchy() * step_size * 0.5\n            new_y = y + np.random.standard_cauchy() * step_size * 0.5\n        else:\n            # Gaussian for fine-tuning\n            angle = np.random.uniform(0, 2 * np.pi)\n            distance = np.random.normal(0, step_size)\n            new_x = x + distance * np.cos(angle)\n            new_y = y + distance * np.sin(angle)\n        new_val = evaluate_function(new_x, new_y)\n        \n        # Accept or reject based on simulated annealing\n        if new_val < val or np.random.random() < np.exp(-(new_val - val) / temp):\n            candidates[idx] = [new_x, new_y, new_val]\n            \n            # Update global best\n            if new_val < best_value:\n                best_x, best_y, best_value = new_x, new_y, new_val\n        \n        # Enhanced local search with gradient information\n        if temp < 0.2 and i % 15 == 0:\n            # Compute approximate gradient\n            eps = 0.001\n            dx = (evaluate_function(best_x + eps, best_y) - evaluate_function(best_x - eps, best_y)) / (2 * eps)\n            dy = (evaluate_function(best_x, best_y + eps) - evaluate_function(best_x, best_y - eps)) / (2 * eps)\n            \n            # Multiple local search strategies\n            for strategy in range(5):\n                if strategy < 2:\n                    # Gradient-based steps\n                    step_size = 0.01 * (1 - strategy * 0.5)\n                    lx = best_x - step_size * dx + np.random.normal(0, 0.01)\n                    ly = best_y - step_size * dy + np.random.normal(0, 0.01)\n                else:\n                    # Random local exploration with decreasing radius\n                    radius = 0.05 * (0.5 ** (strategy - 2))\n                    angle = np.random.uniform(0, 2 * np.pi)\n                    distance = np.random.normal(0, radius)\n                    lx = best_x + distance * np.cos(angle)\n                    ly = best_y + distance * np.sin(angle)\n                \n                lx = np.clip(lx, bounds[0], bounds[1])\n                ly = np.clip(ly, bounds[0], bounds[1])\n                lval = evaluate_function(lx, ly)\n                if lval < best_value:\n                    best_x, best_y, best_value = lx, ly, lval\n                    # Update elite if we found better solution\n                    elite = [best_x, best_y, best_value]\n        \n        # Cool down temperature\n        temp = max(min_temp, temp * temp_decay)\n        \n        # Intelligent restart when stuck\n        if i % 50 == 0 and i > 0:\n            # Check if we're making progress\n            current_best = min(candidates, key=lambda x: x[2])\n            if abs(current_best[2] - best_value) < 1e-6:\n                # Replace worst candidates with explorative jumps\n                candidates.sort(key=lambda x: x[2])\n                for j in range(3):  # Replace 3 worst candidates\n                    # Jump around elite or random location\n                    if np.random.random() < 0.7:\n                        # Jump around elite\n                        jump_x = elite[0] + np.random.normal(0, 1.0)\n                        jump_y = elite[1] + np.random.normal(0, 1.0)\n                    else:\n                        # Completely random restart\n                        jump_x = np.random.uniform(bounds[0], bounds[1])\n                        jump_y = np.random.uniform(bounds[0], bounds[1])\n                    \n                    jump_x = np.clip(jump_x, bounds[0], bounds[1])\n                    jump_y = np.clip(jump_y, bounds[0], bounds[1])\n                    candidates[-(j+1)] = [jump_x, jump_y, evaluate_function(jump_x, jump_y)]\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n", "language": "python", "parent_id": "f21d359e-c0e8-461c-adf1-d3d8e6ad52b7", "generation": 3, "timestamp": 1764999718.4347103, "iteration_found": 24, "metrics": {"runs_successfully": 1.0, "value_score": 0.9996854564491593, "distance_score": 0.9990732028947921, "combined_score": 1.4993470336395258, "reliability_score": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"island": 1}, "prompts": null, "artifacts_json": "{\"stage1_result\": \"Found solution at x=-1.7039, y=0.6781 with value=-1.5187\", \"distance_to_global\": \"0.0002\", \"solution_quality\": \"Distance < 0.5: Very close\", \"convergence_info\": \"Converged in 10 trials with 10 successes\", \"best_position\": \"Final position: x=-1.7048, y=0.6775\", \"average_distance_to_global\": \"0.0009\", \"search_efficiency\": \"Success rate: 100.00%\"}", "artifact_dir": null, "embedding": null}