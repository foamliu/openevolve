{"id": "5f6ea586-fcbe-4c89-b737-568e9ea1aed8", "code": "# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Efficient hybrid search with multiple candidates and adaptive cooling.\n    \"\"\"\n    # Initialize 8 diverse candidates with improved Latin Hypercube sampling\n    candidates = []\n    for i in range(8):\n        # Latin Hypercube sampling for better coverage\n        x = bounds[0] + (i + 0.5) * (bounds[1] - bounds[0]) / 8 + np.random.uniform(-0.3, 0.3)\n        y = bounds[0] + np.random.uniform(0, 8) * (bounds[1] - bounds[0]) / 8 + np.random.uniform(-0.3, 0.3)\n        x = np.clip(x, bounds[0], bounds[1])\n        y = np.clip(y, bounds[0], bounds[1])\n        candidates.append([x, y, evaluate_function(x, y)])\n    \n    # Sort by value and preserve elite\n    candidates.sort(key=lambda x: x[2])\n    best_x, best_y, best_value = candidates[0]\n    elite = candidates[0]  # Preserve best solution\n    \n    # Simulated annealing parameters with slower cooling\n    temp = 2.0\n    temp_decay = 0.995\n    min_temp = 0.01\n    \n    for i in range(iterations):\n        # Select random candidate for exploration\n        idx = np.random.randint(0, len(candidates))\n        x, y, val = candidates[idx]\n        \n        # Adaptive step size based on temperature and progress\n        step_scale = min(1.0, temp) * (1 - i/iterations * 0.8)\n        step_size = step_scale * (bounds[1] - bounds[0]) / 5\n        \n        # Mix exploration strategies based on temperature and progress\n        if temp > 0.5 or np.random.random() < 0.3:\n            # Heavy-tailed Cauchy distribution for better exploration\n            new_x = x + np.random.standard_cauchy() * step_size * 0.5\n            new_y = y + np.random.standard_cauchy() * step_size * 0.5\n        else:\n            # Gaussian for fine-tuning\n            angle = np.random.uniform(0, 2 * np.pi)\n            distance = np.random.normal(0, step_size)\n            new_x = x + distance * np.cos(angle)\n            new_y = y + distance * np.sin(angle)\n        new_val = evaluate_function(new_x, new_y)\n        \n        # Accept or reject based on simulated annealing\n        if new_val < val or np.random.random() < np.exp(-(new_val - val) / temp):\n            candidates[idx] = [new_x, new_y, new_val]\n            \n            # Update global best\n            if new_val < best_value:\n                best_x, best_y, best_value = new_x, new_y, new_val\n        \n        # Enhanced local search with gradient information and multiple strategies\n        if temp < 0.2 and i % 15 == 0:\n            # Compute approximate gradient for gradient-based steps\n            eps = 0.001\n            dx = (evaluate_function(best_x + eps, best_y) - evaluate_function(best_x - eps, best_y)) / (2 * eps)\n            dy = (evaluate_function(best_x, best_y + eps) - evaluate_function(best_x, best_y - eps)) / (2 * eps)\n            \n            # Multiple local search strategies\n            for strategy in range(5):\n                if strategy < 2:\n                    # Gradient-based steps with noise for robustness\n                    step_size = 0.01 * (1 - strategy * 0.5)\n                    lx = best_x - step_size * dx + np.random.normal(0, 0.01)\n                    ly = best_y - step_size * dy + np.random.normal(0, 0.01)\n                elif strategy == 2:\n                    # Pattern search for systematic exploration\n                    step = 0.05\n                    for pdx in [-step, 0, step]:\n                        for pdy in [-step, 0, step]:\n                            if pdx == 0 and pdy == 0:\n                                continue\n                            lx = best_x + pdx\n                            ly = best_y + pdy\n                            lx = np.clip(lx, bounds[0], bounds[1])\n                            ly = np.clip(ly, bounds[0], bounds[1])\n                            lval = evaluate_function(lx, ly)\n                            if lval < best_value:\n                                best_x, best_y, best_value = lx, ly, lval\n                                elite = [best_x, best_y, best_value]\n                    continue\n                else:\n                    # Random local exploration with decreasing radius\n                    radius = 0.03 * (0.5 ** (strategy - 3))\n                    angle = np.random.uniform(0, 2 * np.pi)\n                    distance = np.random.normal(0, radius)\n                    lx = best_x + distance * np.cos(angle)\n                    ly = best_y + distance * np.sin(angle)\n                \n                lx = np.clip(lx, bounds[0], bounds[1])\n                ly = np.clip(ly, bounds[0], bounds[1])\n                lval = evaluate_function(lx, ly)\n                if lval < best_value:\n                    best_x, best_y, best_value = lx, ly, lval\n                    elite = [best_x, best_y, best_value]\n        \n        # Cool down temperature\n        temp = max(min_temp, temp * temp_decay)\n        \n        # Intelligent restart when stuck\n        if i % 50 == 0 and i > 0:\n            # Check if we're making progress\n            current_best = min(candidates, key=lambda x: x[2])\n            if abs(current_best[2] - best_value) < 1e-6:\n                # Replace worst candidates with explorative jumps\n                candidates.sort(key=lambda x: x[2])\n                for j in range(3):  # Replace 3 worst candidates\n                    # Jump around elite or random location\n                    if np.random.random() < 0.7:\n                        # Jump around elite for targeted exploration\n                        jump_x = elite[0] + np.random.normal(0, 1.0)\n                        jump_y = elite[1] + np.random.normal(0, 1.0)\n                    else:\n                        # Completely random restart for diversity\n                        jump_x = np.random.uniform(bounds[0], bounds[1])\n                        jump_y = np.random.uniform(bounds[0], bounds[1])\n                    \n                    jump_x = np.clip(jump_x, bounds[0], bounds[1])\n                    jump_y = np.clip(jump_y, bounds[0], bounds[1])\n                    candidates[-(j+1)] = [jump_x, jump_y, evaluate_function(jump_x, jump_y)]\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n", "language": "python", "parent_id": "af42081d-1b99-4c0f-8c51-13162857d3c9", "generation": 5, "timestamp": 1765000524.2446353, "iteration_found": 32, "metrics": {"runs_successfully": 1.0, "value_score": 0.9996848994838796, "distance_score": 0.9989674906398256, "combined_score": 1.499299045400831, "reliability_score": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 16 lines with 44 lines\nChange 2: Replace 12 lines with 9 lines\nChange 3: Replace 19 lines with 21 lines\nChange 4: Replace 4 lines with 4 lines", "parent_metrics": {"runs_successfully": 1.0, "value_score": 0.9800270245536994, "distance_score": 0.5526089767183535, "combined_score": 1.0269554463508268, "reliability_score": 1.0}, "island": 2}, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve a function minimization algorithm to find the global minimum of a complex function with many local minima. The function is f(x, y) = sin(x) * cos(y) + sin(x*y) + (x^2 + y^2)/20. Focus on improving the search_algorithm function to reliably find the global minimum, escaping local minima that might trap simple algorithms.", "user": "# Current Program Information\n- Fitness: 1.0270\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness unchanged at 1.0270\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### stage1_result\n```\nFound solution at x=-1.7160, y=0.6910 with value=-1.5182\n```\n\n### distance_to_global\n```\n0.0177\n```\n\n### solution_quality\n```\nDistance < 0.5: Very close\n```\n\n### convergence_info\n```\nConverged in 10 trials with 10 successes\n```\n\n### best_position\n```\nFinal position: x=-1.7015, y=0.6694\n```\n\n### average_distance_to_global\n```\n0.8096\n```\n\n### search_efficiency\n```\nSuccess rate: 100.00%\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 2\n- Changes: Change 1: Replace 9 lines with 12 lines\nChange 2: Replace 29 lines with 16 lines\nChange 3: Replace 21 lines with 19 lines\nChange 4: Replace 4 lines with 4 lines\n- Metrics: runs_successfully: 1.0000, value_score: 0.9800, distance_score: 0.5526, combined_score: 1.0270, reliability_score: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: runs_successfully: 1.0000, value_score: 0.9997, distance_score: 0.9991, combined_score: 1.4993, reliability_score: 1.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.4993)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Efficient hybrid search with multiple candidates and adaptive cooling.\n    \"\"\"\n    # Initialize 8 diverse candidates with Latin Hypercube sampling\n    candidates = []\n    for i in range(8):\n        # Latin Hypercube sampling for better coverage\n        x = bounds[0] + (i + 0.5) * (bounds[1] - bounds[0]) / 8 + np.random.uniform(-0.3, 0.3)\n        y = bounds[0] + np.random.uniform(0, 8) * (bounds[1] - bounds[0]) / 8 + np.random.uniform(-0.3, 0.3)\n        x = np.clip(x, bounds[0], bounds[1])\n        y = np.clip(y, bounds[0], bounds[1])\n        candidates.append([x, y, evaluate_function(x, y)])\n    \n    # Sort by value and preserve elite\n    candidates.sort(key=lambda x: x[2])\n    best_x, best_y, best_value = candidates[0]\n    elite = candidates[0]  # Preserve best solution\n    \n    # Simulated annealing parameters\n    temp = 2.0\n    temp_decay = 0.995\n    min_temp = 0.01\n    \n    for i in range(iterations):\n        # Select random candidate for exploration\n        idx = np.random.randint(0, len(candidates))\n        x, y, val = candidates[idx]\n        \n        # Adaptive step size based on temperature and progress\n        step_scale = min(1.0, temp) * (1 - i/iterations * 0.8)\n        step_size = step_scale * (bounds[1] - bounds[0]) / 5\n        \n        # Mix exploration strategies based on temperature and progress\n        if temp > 0.5 or np.random.random() < 0.3:\n            # Heavy-tailed Cauchy distribution for better exploration\n            new_x = x + np.random.standard_cauchy() * step_size * 0.5\n            new_y = y + np.random.standard_cauchy() * step_size * 0.5\n        else:\n            # Gaussian for fine-tuning\n            angle = np.random.uniform(0, 2 * np.pi)\n            distance = np.random.normal(0, step_size)\n            new_x = x + distance * np.cos(angle)\n            new_y = y + distance * np.sin(angle)\n        new_val = evaluate_function(new_x, new_y)\n        \n        # Accept or reject based on simulated annealing\n        if new_val < val or np.random.random() < np.exp(-(new_val - val) / temp):\n            candidates[idx] = [new_x, new_y, new_val]\n            \n            # Update global best\n            if new_val < best_value:\n                best_x, best_y, best_value = new_x, new_y, new_val\n        \n        # Enhanced local search with gradient information\n        if temp < 0.2 and i % 15 == 0:\n            # Compute approximate gradient\n            eps = 0.001\n            dx = (evaluate_function(best_x + eps, best_y) - evaluate_function(best_x - eps, best_y)) / (2 * eps)\n            dy = (evaluate_function(best_x, best_y + eps) - evaluate_function(best_x, best_y - eps)) / (2 * eps)\n            \n            # Multiple local search strategies\n            for strategy in range(5):\n                if strategy < 2:\n                    # Gradient-based steps\n                    step_size = 0.01 * (1 - strategy * 0.5)\n                    lx = best_x - step_size * dx + np.random.normal(0, 0.01)\n                    ly = best_y - step_size * dy + np.random.normal(0, 0.01)\n                else:\n                    # Random local exploration with decreasing radius\n                    radius = 0.05 * (0.5 ** (strategy - 2))\n                    angle = np.random.uniform(0, 2 * np.pi)\n                    distance = np.random.normal(0, radius)\n                    lx = best_x + distance * np.cos(angle)\n                    ly = best_y + distance * np.sin(angle)\n                \n                lx = np.clip(lx, bounds[0], bounds[1])\n                ly = np.clip(ly, bounds[0], bounds[1])\n                lval = evaluate_function(lx, ly)\n                if lval < best_value:\n                    best_x, best_y, best_value = lx, ly, lval\n                    # Update elite if we found better solution\n                    elite = [best_x, best_y, best_value]\n        \n        # Cool down temperature\n        temp = max(min_temp, temp * temp_decay)\n        \n        # Intelligent restart when stuck\n        if i % 50 == 0 and i > 0:\n            # Check if we're making progress\n            current_best = min(candidates, key=lambda x: x[2])\n            if abs(current_best[2] - best_value) < 1e-6:\n                # Replace worst candidates with explorative jumps\n                candidates.sort(key=lambda x: x[2])\n                for j in range(3):  # Replace 3 worst candidates\n                    # Jump around elite or random location\n                    if np.random.random() < 0.7:\n                        # Jump around elite\n                        jump_x = elite[0] + np.random.normal(0, 1.0)\n                        jump_y = elite[1] + np.random.normal(0, 1.0)\n                    else:\n                        # Completely random restart\n                        jump_x = np.random.uniform(bounds[0], bounds[1])\n                        jump_y = np.random.uniform(bounds[0], bounds[1])\n                    \n                    jump_x = np.clip(jump_x, bounds[0], bounds[1])\n                    jump_y = np.clip(jump_y, bounds[0], bounds[1])\n                    candidates[-(j+1)] = [jump_x, jump_y, evaluate_function(jump_x, jump_y)]\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9997), Performs well on distance_score (0.9991), Performs well on combined_score (1.4993), Performs well on reliability_score (1.0000)\n\n### Program 2 (Score: 1.0270)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Efficient hybrid search with multiple candidates and adaptive cooling.\n    \"\"\"\n    # Initialize 8 diverse candidates with Latin Hypercube sampling\n    candidates = []\n    for i in range(8):\n        # Latin Hypercube sampling for better coverage\n        x = bounds[0] + (i + 0.5) * (bounds[1] - bounds[0]) / 8\n        y = bounds[0] + ((i * 3) % 8 + 0.5) * (bounds[1] - bounds[0]) / 8\n        # Add small random perturbation\n        x += np.random.uniform(-0.2, 0.2)\n        y += np.random.uniform(-0.2, 0.2)\n        x = np.clip(x, bounds[0], bounds[1])\n        y = np.clip(y, bounds[0], bounds[1])\n        candidates.append([x, y, evaluate_function(x, y)])\n    \n    # Sort by value and preserve elite\n    candidates.sort(key=lambda x: x[2])\n    best_x, best_y, best_value = candidates[0]\n    elite = candidates[0]  # Preserve best solution\n    \n    # Adaptive simulated annealing parameters\n    temp = 1.5\n    temp_decay = 0.992\n    min_temp = 0.005\n    \n    for i in range(iterations):\n        # Select random candidate for exploration\n        idx = np.random.randint(0, len(candidates))\n        x, y, val = candidates[idx]\n        \n        # Adaptive step size based on temperature and progress\n        step_scale = min(1.0, temp) * (1 - i/iterations * 0.8)\n        step_size = step_scale * (bounds[1] - bounds[0]) / 5\n        \n        # Mix exploration strategies based on temperature and progress\n        if temp > 0.5 or np.random.random() < 0.3:\n            # Heavy-tailed Cauchy distribution for better exploration\n            new_x = x + np.random.standard_cauchy() * step_size * 0.5\n            new_y = y + np.random.standard_cauchy() * step_size * 0.5\n        else:\n            # Gaussian for fine-tuning\n            angle = np.random.uniform(0, 2 * np.pi)\n            distance = np.random.normal(0, step_size)\n            new_x = x + distance * np.cos(angle)\n            new_y = y + distance * np.sin(angle)\n        new_val = evaluate_function(new_x, new_y)\n        \n        # Accept or reject based on simulated annealing\n        if new_val < val or np.random.random() < np.exp(-(new_val - val) / temp):\n            candidates[idx] = [new_x, new_y, new_val]\n            \n            # Update global best\n            if new_val < best_value:\n                best_x, best_y, best_value = new_x, new_y, new_val\n        \n        # Efficient local search with pattern search\n        if temp < 0.2 and i % 20 == 0:\n            # Pattern search with decreasing step size\n            step = 0.1 * (0.9 ** (i // 100))\n            for dx in [-step, 0, step]:\n                for dy in [-step, 0, step]:\n                    if dx == 0 and dy == 0:\n                        continue\n                    lx = best_x + dx\n                    ly = best_y + dy\n                    lx = np.clip(lx, bounds[0], bounds[1])\n                    ly = np.clip(ly, bounds[0], bounds[1])\n                    lval = evaluate_function(lx, ly)\n                    if lval < best_value:\n                        best_x, best_y, best_value = lx, ly, lval\n                        elite = [best_x, best_y, best_value]\n        \n        # Cool down temperature\n        temp = max(min_temp, temp * temp_decay)\n        \n        # Adaptive restart when stuck\n        if i % 60 == 0 and i > 0:\n            candidates.sort(key=lambda x: x[2])\n            # Check diversity: if best and worst are too close, restart\n            if candidates[-1][2] - candidates[0][2] < 0.1:\n                # Replace worst half with diverse samples\n                for j in range(4):\n                    if np.random.random() < 0.6:\n                        # Explorative jump from best\n                        jump_x = candidates[0][0] + np.random.normal(0, 2.0)\n                        jump_y = candidates[0][1] + np.random.normal(0, 2.0)\n                    else:\n                        # Random restart\n                        jump_x = np.random.uniform(bounds[0], bounds[1])\n                        jump_y = np.random.uniform(bounds[0], bounds[1])\n                    \n                    jump_x = np.clip(jump_x, bounds[0], bounds[1])\n                    jump_y = np.clip(jump_y, bounds[0], bounds[1])\n                    candidates[-(j+1)] = [jump_x, jump_y, evaluate_function(jump_x, jump_y)]\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9800), Performs well on distance_score (0.5526), Performs well on combined_score (1.0270), Performs well on reliability_score (1.0000)\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 1.4993, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Efficient hybrid search with multiple candidates and adaptive cooling.\n    \"\"\"\n    # Initialize 8 diverse candidates with Latin Hypercube sampling\n    candidates = []\n    for i in range(8):\n        # Latin Hypercube sampling for better coverage\n        x = bounds[0] + (i + 0.5) * (bounds[1] - bounds[0]) / 8 + np.random.uniform(-0.3, 0.3)\n        y = bounds[0] + np.random.uniform(0, 8) * (bounds[1] - bounds[0]) / 8 + np.random.uniform(-0.3, 0.3)\n        x = np.clip(x, bounds[0], bounds[1])\n        y = np.clip(y, bounds[0], bounds[1])\n        candidates.append([x, y, evaluate_function(x, y)])\n    \n    # Sort by value and preserve elite\n    candidates.sort(key=lambda x: x[2])\n    best_x, best_y, best_value = candidates[0]\n    elite = candidates[0]  # Preserve best solution\n    \n    # Simulated annealing parameters\n    temp = 2.0\n    temp_decay = 0.995\n    min_temp = 0.01\n    \n    for i in range(iterations):\n        # Select random candidate for exploration\n        idx = np.random.randint(0, len(candidates))\n        x, y, val = candidates[idx]\n        \n        # Adaptive step size based on temperature and progress\n        step_scale = min(1.0, temp) * (1 - i/iterations * 0.8)\n        step_size = step_scale * (bounds[1] - bounds[0]) / 5\n        \n        # Mix exploration strategies based on temperature and progress\n        if temp > 0.5 or np.random.random() < 0.3:\n            # Heavy-tailed Cauchy distribution for better exploration\n            new_x = x + np.random.standard_cauchy() * step_size * 0.5\n            new_y = y + np.random.standard_cauchy() * step_size * 0.5\n        else:\n            # Gaussian for fine-tuning\n            angle = np.random.uniform(0, 2 * np.pi)\n            distance = np.random.normal(0, step_size)\n            new_x = x + distance * np.cos(angle)\n            new_y = y + distance * np.sin(angle)\n        new_val = evaluate_function(new_x, new_y)\n        \n        # Accept or reject based on simulated annealing\n        if new_val < val or np.random.random() < np.exp(-(new_val - val) / temp):\n            candidates[idx] = [new_x, new_y, new_val]\n            \n            # Update global best\n            if new_val < best_value:\n                best_x, best_y, best_value = new_x, new_y, new_val\n        \n        # Enhanced local search with gradient information\n        if temp < 0.2 and i % 15 == 0:\n            # Compute approximate gradient\n            eps = 0.001\n            dx = (evaluate_function(best_x + eps, best_y) - evaluate_function(best_x - eps, best_y)) / (2 * eps)\n            dy = (evaluate_function(best_x, best_y + eps) - evaluate_function(best_x, best_y - eps)) / (2 * eps)\n            \n            # Multiple local search strategies\n            for strategy in range(5):\n                if strategy < 2:\n                    # Gradient-based steps\n                    step_size = 0.01 * (1 - strategy * 0.5)\n                    lx = best_x - step_size * dx + np.random.normal(0, 0.01)\n                    ly = best_y - step_size * dy + np.random.normal(0, 0.01)\n                else:\n                    # Random local exploration with decreasing radius\n                    radius = 0.05 * (0.5 ** (strategy - 2))\n                    angle = np.random.uniform(0, 2 * np.pi)\n                    distance = np.random.normal(0, radius)\n                    lx = best_x + distance * np.cos(angle)\n                    ly = best_y + distance * np.sin(angle)\n                \n                lx = np.clip(lx, bounds[0], bounds[1])\n                ly = np.clip(ly, bounds[0], bounds[1])\n                lval = evaluate_function(lx, ly)\n                if lval < best_value:\n                    best_x, best_y, best_value = lx, ly, lval\n                    # Update elite if we found better solution\n                    elite = [best_x, best_y, best_value]\n        \n        # Cool down temperature\n        temp = max(min_temp, temp * temp_decay)\n        \n        # Intelligent restart when stuck\n        if i % 50 == 0 and i > 0:\n            # Check if we're making progress\n            current_best = min(candidates, key=lambda x: x[2])\n            if abs(current_best[2] - best_value) < 1e-6:\n                # Replace worst candidates with explorative jumps\n                candidates.sort(key=lambda x: x[2])\n                for j in range(3):  # Replace 3 worst candidates\n                    # Jump around elite or random location\n                    if np.random.random() < 0.7:\n                        # Jump around elite\n                        jump_x = elite[0] + np.random.normal(0, 1.0)\n                        jump_y = elite[1] + np.random.normal(0, 1.0)\n                    else:\n                        # Completely random restart\n                        jump_x = np.random.uniform(bounds[0], bounds[1])\n                        jump_y = np.random.uniform(bounds[0], bounds[1])\n                    \n                    jump_x = np.clip(jump_x, bounds[0], bounds[1])\n                    jump_y = np.clip(jump_y, bounds[0], bounds[1])\n                    candidates[-(j+1)] = [jump_x, jump_y, evaluate_function(jump_x, jump_y)]\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Excellent runs_successfully (1.000), Excellent value_score (1.000), Excellent distance_score (0.999)\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Efficient hybrid search with multiple candidates and adaptive cooling.\n    \"\"\"\n    # Initialize 8 diverse candidates with Latin Hypercube sampling\n    candidates = []\n    for i in range(8):\n        # Latin Hypercube sampling for better coverage\n        x = bounds[0] + (i + 0.5) * (bounds[1] - bounds[0]) / 8\n        y = bounds[0] + ((i * 3) % 8 + 0.5) * (bounds[1] - bounds[0]) / 8\n        # Add small random perturbation\n        x += np.random.uniform(-0.2, 0.2)\n        y += np.random.uniform(-0.2, 0.2)\n        x = np.clip(x, bounds[0], bounds[1])\n        y = np.clip(y, bounds[0], bounds[1])\n        candidates.append([x, y, evaluate_function(x, y)])\n    \n    # Sort by value and preserve elite\n    candidates.sort(key=lambda x: x[2])\n    best_x, best_y, best_value = candidates[0]\n    elite = candidates[0]  # Preserve best solution\n    \n    # Adaptive simulated annealing parameters\n    temp = 1.5\n    temp_decay = 0.992\n    min_temp = 0.005\n    \n    for i in range(iterations):\n        # Select random candidate for exploration\n        idx = np.random.randint(0, len(candidates))\n        x, y, val = candidates[idx]\n        \n        # Adaptive step size based on temperature and progress\n        step_scale = min(1.0, temp) * (1 - i/iterations * 0.8)\n        step_size = step_scale * (bounds[1] - bounds[0]) / 5\n        \n        # Mix exploration strategies based on temperature and progress\n        if temp > 0.5 or np.random.random() < 0.3:\n            # Heavy-tailed Cauchy distribution for better exploration\n            new_x = x + np.random.standard_cauchy() * step_size * 0.5\n            new_y = y + np.random.standard_cauchy() * step_size * 0.5\n        else:\n            # Gaussian for fine-tuning\n            angle = np.random.uniform(0, 2 * np.pi)\n            distance = np.random.normal(0, step_size)\n            new_x = x + distance * np.cos(angle)\n            new_y = y + distance * np.sin(angle)\n        new_val = evaluate_function(new_x, new_y)\n        \n        # Accept or reject based on simulated annealing\n        if new_val < val or np.random.random() < np.exp(-(new_val - val) / temp):\n            candidates[idx] = [new_x, new_y, new_val]\n            \n            # Update global best\n            if new_val < best_value:\n                best_x, best_y, best_value = new_x, new_y, new_val\n        \n        # Efficient local search with pattern search\n        if temp < 0.2 and i % 20 == 0:\n            # Pattern search with decreasing step size\n            step = 0.1 * (0.9 ** (i // 100))\n            for dx in [-step, 0, step]:\n                for dy in [-step, 0, step]:\n                    if dx == 0 and dy == 0:\n                        continue\n                    lx = best_x + dx\n                    ly = best_y + dy\n                    lx = np.clip(lx, bounds[0], bounds[1])\n                    ly = np.clip(ly, bounds[0], bounds[1])\n                    lval = evaluate_function(lx, ly)\n                    if lval < best_value:\n                        best_x, best_y, best_value = lx, ly, lval\n                        elite = [best_x, best_y, best_value]\n        \n        # Cool down temperature\n        temp = max(min_temp, temp * temp_decay)\n        \n        # Adaptive restart when stuck\n        if i % 60 == 0 and i > 0:\n            candidates.sort(key=lambda x: x[2])\n            # Check diversity: if best and worst are too close, restart\n            if candidates[-1][2] - candidates[0][2] < 0.1:\n                # Replace worst half with diverse samples\n                for j in range(4):\n                    if np.random.random() < 0.6:\n                        # Explorative jump from best\n                        jump_x = candidates[0][0] + np.random.normal(0, 2.0)\n                        jump_y = candidates[0][1] + np.random.normal(0, 2.0)\n                    else:\n                        # Random restart\n                        jump_x = np.random.uniform(bounds[0], bounds[1])\n                        jump_y = np.random.uniform(bounds[0], bounds[1])\n                    \n                    jump_x = np.clip(jump_x, bounds[0], bounds[1])\n                    jump_y = np.clip(jump_y, bounds[0], bounds[1])\n                    candidates[-(j+1)] = [jump_x, jump_y, evaluate_function(jump_x, jump_y)]\n    \n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program and the performance metrics, I can see that while it has good reliability (100% success rate), its distance_score is significantly lower than the top performer (0.5526 vs 0.9991). This suggests the algorithm is finding solutions but not consistently getting very close to the true global minimum.\n\nLet me analyze the key differences between the current program and the top performer:\n\n1. The top performer uses gradient information for local search\n2. It has more sophisticated restart mechanisms\n3. It maintains an \"elite\" solution separately and uses it for intelligent restarts\n4. It has more diverse local search strategies\n\nHere are my targeted improvements:\n\n## Change 1: Add gradient-based local search\n\nThe current program only uses pattern search for local optimization. Adding gradient information will help converge more precisely to local minima.\n\n```python\n<<<<<<< SEARCH\n        # Efficient local search with pattern search\n        if temp < 0.2 and i % 20 == 0:\n            # Pattern search with decreasing step size\n            step = 0.1 * (0.9 ** (i // 100))\n            for dx in [-step, 0, step]:\n                for dy in [-step, 0, step]:\n                    if dx == 0 and dy == 0:\n                        continue\n                    lx = best_x + dx\n                    ly = best_y + dy\n                    lx = np.clip(lx, bounds[0], bounds[1])\n                    ly = np.clip(ly, bounds[0], bounds[1])\n                    lval = evaluate_function(lx, ly)\n                    if lval < best_value:\n                        best_x, best_y, best_value = lx, ly, lval\n                        elite = [best_x, best_y, best_value]\n=======\n        # Enhanced local search with gradient information and multiple strategies\n        if temp < 0.2 and i % 15 == 0:\n            # Compute approximate gradient for gradient-based steps\n            eps = 0.001\n            dx = (evaluate_function(best_x + eps, best_y) - evaluate_function(best_x - eps, best_y)) / (2 * eps)\n            dy = (evaluate_function(best_x, best_y + eps) - evaluate_function(best_x, best_y - eps)) / (2 * eps)\n            \n            # Multiple local search strategies\n            for strategy in range(5):\n                if strategy < 2:\n                    # Gradient-based steps with noise for robustness\n                    step_size = 0.01 * (1 - strategy * 0.5)\n                    lx = best_x - step_size * dx + np.random.normal(0, 0.01)\n                    ly = best_y - step_size * dy + np.random.normal(0, 0.01)\n                elif strategy == 2:\n                    # Pattern search for systematic exploration\n                    step = 0.05\n                    for pdx in [-step, 0, step]:\n                        for pdy in [-step, 0, step]:\n                            if pdx == 0 and pdy == 0:\n                                continue\n                            lx = best_x + pdx\n                            ly = best_y + pdy\n                            lx = np.clip(lx, bounds[0], bounds[1])\n                            ly = np.clip(ly, bounds[0], bounds[1])\n                            lval = evaluate_function(lx, ly)\n                            if lval < best_value:\n                                best_x, best_y, best_value = lx, ly, lval\n                                elite = [best_x, best_y, best_value]\n                    continue\n                else:\n                    # Random local exploration with decreasing radius\n                    radius = 0.03 * (0.5 ** (strategy - 3))\n                    angle = np.random.uniform(0, 2 * np.pi)\n                    distance = np.random.normal(0, radius)\n                    lx = best_x + distance * np.cos(angle)\n                    ly = best_y + distance * np.sin(angle)\n                \n                lx = np.clip(lx, bounds[0], bounds[1])\n                ly = np.clip(ly, bounds[0], bounds[1])\n                lval = evaluate_function(lx, ly)\n                if lval < best_value:\n                    best_x, best_y, best_value = lx, ly, lval\n                    elite = [best_x, best_y, best_value]\n>>>>>>> REPLACE\n```\n\n## Change 2: Improve initialization with better diversity\n\nThe current initialization is good but can be enhanced for better coverage of the search space.\n\n```python\n<<<<<<< SEARCH\n    # Initialize 8 diverse candidates with Latin Hypercube sampling\n    candidates = []\n    for i in range(8):\n        # Latin Hypercube sampling for better coverage\n        x = bounds[0] + (i + 0.5) * (bounds[1] - bounds[0]) / 8\n        y = bounds[0] + ((i * 3) % 8 + 0.5) * (bounds[1] - bounds[0]) / 8\n        # Add small random perturbation\n        x += np.random.uniform(-0.2, 0.2)\n        y += np.random.uniform(-0.2, 0.2)\n        x = np.clip(x, bounds[0], bounds[1])\n        y = np.clip(y, bounds[0], bounds[1])\n        candidates.append([x, y, evaluate_function(x, y)])\n=======\n    # Initialize 8 diverse candidates with improved Latin Hypercube sampling\n    candidates = []\n    for i in range(8):\n        # Latin Hypercube sampling for better coverage\n        x = bounds[0] + (i + 0.5) * (bounds[1] - bounds[0]) / 8 + np.random.uniform(-0.3, 0.3)\n        y = bounds[0] + np.random.uniform(0, 8) * (bounds[1] - bounds[0]) / 8 + np.random.uniform(-0.3, 0.3)\n        x = np.clip(x, bounds[0], bounds[1])\n        y = np.clip(y, bounds[0], bounds[1])\n        candidates.append([x, y, evaluate_function(x, y)])\n>>>>>>> REPLACE\n```\n\n## Change 3: Enhance restart mechanism with elite preservation\n\nThe current restart mechanism is too conservative. We need more intelligent restarts that use the elite solution.\n\n```python\n<<<<<<< SEARCH\n        # Adaptive restart when stuck\n        if i % 60 == 0 and i > 0:\n            candidates.sort(key=lambda x: x[2])\n            # Check diversity: if best and worst are too close, restart\n            if candidates[-1][2] - candidates[0][2] < 0.1:\n                # Replace worst half with diverse samples\n                for j in range(4):\n                    if np.random.random() < 0.6:\n                        # Explorative jump from best\n                        jump_x = candidates[0][0] + np.random.normal(0, 2.0)\n                        jump_y = candidates[0][1] + np.random.normal(0, 2.0)\n                    else:\n                        # Random restart\n                        jump_x = np.random.uniform(bounds[0], bounds[1])\n                        jump_y = np.random.uniform(bounds[0], bounds[1])\n                    \n                    jump_x = np.clip(jump_x, bounds[0], bounds[1])\n                    jump_y = np.clip(jump_y, bounds[0], bounds[1])\n                    candidates[-(j+1)] = [jump_x, jump_y, evaluate_function(jump_x, jump_y)]\n=======\n        # Intelligent restart when stuck\n        if i % 50 == 0 and i > 0:\n            # Check if we're making progress\n            current_best = min(candidates, key=lambda x: x[2])\n            if abs(current_best[2] - best_value) < 1e-6:\n                # Replace worst candidates with explorative jumps\n                candidates.sort(key=lambda x: x[2])\n                for j in range(3):  # Replace 3 worst candidates\n                    # Jump around elite or random location\n                    if np.random.random() < 0.7:\n                        # Jump around elite for targeted exploration\n                        jump_x = elite[0] + np.random.normal(0, 1.0)\n                        jump_y = elite[1] + np.random.normal(0, 1.0)\n                    else:\n                        # Completely random restart for diversity\n                        jump_x = np.random.uniform(bounds[0], bounds[1])\n                        jump_y = np.random.uniform(bounds[0], bounds[1])\n                    \n                    jump_x = np.clip(jump_x, bounds[0], bounds[1])\n                    jump_y = np.clip(jump_y, bounds[0], bounds[1])\n                    candidates[-(j+1)] = [jump_x, jump_y, evaluate_function(jump_x, jump_y)]\n>>>>>>> REPLACE\n```\n\n## Change 4: Fine-tune temperature parameters\n\nThe current temperature parameters are too aggressive. We need a slower cooling schedule for better exploration.\n\n```python\n<<<<<<< SEARCH\n    # Adaptive simulated annealing parameters\n    temp = 1.5\n    temp_decay = 0.992\n    min_temp = 0.005\n=======\n    # Simulated annealing parameters with slower cooling\n    temp = 2.0\n    temp_decay = 0.995\n    min_temp = 0.01\n>>>>>>> REPLACE\n```\n\nThese changes combine the best features from the top performer while maintaining the current program's structure. The key improvements are:\n\n1. **Gradient-based local search**: This will help the algorithm converge more precisely to local minima\n2. **Better initialization**: More diverse starting points for better coverage\n3. **Intelligent restarts**: Using the elite solution for targeted exploration when stuck\n4. **Slower cooling schedule**: More thorough exploration of the search space\n\nThese modifications should significantly improve the distance_score while maintaining the high reliability of the current implementation."]}}, "artifacts_json": "{\"stage1_result\": \"Found solution at x=-1.7043, y=0.6773 with value=-1.5187\", \"distance_to_global\": \"0.0007\", \"solution_quality\": \"Distance < 0.5: Very close\", \"convergence_info\": \"Converged in 10 trials with 10 successes\", \"best_position\": \"Final position: x=-1.7056, y=0.6781\", \"average_distance_to_global\": \"0.0010\", \"search_efficiency\": \"Success rate: 100.00%\"}", "artifact_dir": null, "embedding": null}